{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a337556c4ef424ea72950d6233f2a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35a0bbed6e574e3889ec80b404fe90af",
              "IPY_MODEL_8f756c08358a4887a53ec0609049e76d",
              "IPY_MODEL_50018394dc3c49e59d1ec740cde58235",
              "IPY_MODEL_953e1e48927641b4907333493cf95fbd"
            ],
            "layout": "IPY_MODEL_726ca01df0f34e239eb24a0716f578cb"
          }
        },
        "3fe8e2b7ec434e148248311814663fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9e9a7e169b04a8aa2b8e4fd90e87f08",
            "placeholder": "​",
            "style": "IPY_MODEL_3e0102bd97c64f4ab068a3c98c5848a2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3bbad9824d5f47b0b20996ad249c1972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7aa7c64cafdb4158ac710cacf3e303b5",
            "placeholder": "​",
            "style": "IPY_MODEL_f14695be3b574f88b3e71927cd6caedb",
            "value": ""
          }
        },
        "4b1fed1b6cd349078813443c822d6d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_ef05db0ec6664ef3a70fe330e0c12e95",
            "style": "IPY_MODEL_6ef4cda19c074ef9aaa0a051be206d2e",
            "value": true
          }
        },
        "7914978ce0e94af7b7b76e7add58c981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_392418d73c79453ebbdbd82a54f481e6",
            "style": "IPY_MODEL_0184fdc8e93548dfa2bd582117322a4e",
            "tooltip": ""
          }
        },
        "c0dbec7a9a37479b8a0d1b912446cfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7590473761494b9eb142e46c4078328e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e90996d0d754a6faef227188cd58415",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "726ca01df0f34e239eb24a0716f578cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c9e9a7e169b04a8aa2b8e4fd90e87f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0102bd97c64f4ab068a3c98c5848a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa7c64cafdb4158ac710cacf3e303b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14695be3b574f88b3e71927cd6caedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef05db0ec6664ef3a70fe330e0c12e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef4cda19c074ef9aaa0a051be206d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "392418d73c79453ebbdbd82a54f481e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0184fdc8e93548dfa2bd582117322a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7590473761494b9eb142e46c4078328e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e90996d0d754a6faef227188cd58415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97ae6f5070ed450da6a6a471408d4aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf3b28c360b548b88a84373b585c4665",
            "placeholder": "​",
            "style": "IPY_MODEL_2a7dae5eb00d4b5083177a62bddde1e0",
            "value": "Connecting..."
          }
        },
        "cf3b28c360b548b88a84373b585c4665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a7dae5eb00d4b5083177a62bddde1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35a0bbed6e574e3889ec80b404fe90af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbf675899cc4b8e93ee4872dd83b505",
            "placeholder": "​",
            "style": "IPY_MODEL_518d157ac5eb41a4aebc2bab68dc7d20",
            "value": "Token is valid (permission: write)."
          }
        },
        "8f756c08358a4887a53ec0609049e76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32e26fcb2f94c3a852845c2a4916c9b",
            "placeholder": "​",
            "style": "IPY_MODEL_6cdfb195480242bcb9da574d01a483a6",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "50018394dc3c49e59d1ec740cde58235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ad454fda8f4dc3ba56e4498397b334",
            "placeholder": "​",
            "style": "IPY_MODEL_6232ce6ba70d4960915991f9a208dea7",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "953e1e48927641b4907333493cf95fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7dd5b9a90a4cd085a6853802359f20",
            "placeholder": "​",
            "style": "IPY_MODEL_8079784ed7bf41b1b57ad073a370231e",
            "value": "Login successful"
          }
        },
        "adbf675899cc4b8e93ee4872dd83b505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518d157ac5eb41a4aebc2bab68dc7d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c32e26fcb2f94c3a852845c2a4916c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdfb195480242bcb9da574d01a483a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ad454fda8f4dc3ba56e4498397b334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6232ce6ba70d4960915991f9a208dea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e7dd5b9a90a4cd085a6853802359f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8079784ed7bf41b1b57ad073a370231e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e1a95311b643929184e8f8b38272b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f69063ac618d4173bffcaa34947bd22c",
              "IPY_MODEL_8db7bc57008943f4b9c37e39ddb52946",
              "IPY_MODEL_83248c52c8cc4e6f81c3db2691e549c5"
            ],
            "layout": "IPY_MODEL_4b62a6eee2404dbfa625041a0740ed30"
          }
        },
        "f69063ac618d4173bffcaa34947bd22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_386a5dc1c4904dc7a5d0a27a6f4157d0",
            "placeholder": "​",
            "style": "IPY_MODEL_afb9efafbdac429492c0513f36b64d02",
            "value": "Map: 100%"
          }
        },
        "8db7bc57008943f4b9c37e39ddb52946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b54fce84d2448d28852c378d87954f3",
            "max": 59310,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_380bec7c43844ac29ebc983bf570e901",
            "value": 59310
          }
        },
        "83248c52c8cc4e6f81c3db2691e549c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0a9953413540cc94b2242174e991ca",
            "placeholder": "​",
            "style": "IPY_MODEL_2795de2d4b86494694446770ed648ab6",
            "value": " 59310/59310 [00:03&lt;00:00, 15419.55 examples/s]"
          }
        },
        "4b62a6eee2404dbfa625041a0740ed30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386a5dc1c4904dc7a5d0a27a6f4157d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb9efafbdac429492c0513f36b64d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b54fce84d2448d28852c378d87954f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380bec7c43844ac29ebc983bf570e901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a0a9953413540cc94b2242174e991ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2795de2d4b86494694446770ed648ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af4d1871474f45c1a38bd68e6ffe8c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a78d148b19f41b98b131b65a2fd80af",
              "IPY_MODEL_41eac013db7c4a0e94dde0e371debeb0",
              "IPY_MODEL_bf49daa1bdc64b31bb411b7d73250332"
            ],
            "layout": "IPY_MODEL_e1d23ca1ca9b49539a8f90363831fb87"
          }
        },
        "2a78d148b19f41b98b131b65a2fd80af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559eba48188d4a388b78d687d67cf97d",
            "placeholder": "​",
            "style": "IPY_MODEL_1d9e71529a0d4906841ca252ba98b734",
            "value": "Map: 100%"
          }
        },
        "41eac013db7c4a0e94dde0e371debeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbfc4f8174944a5385b553506f460f93",
            "max": 5129,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b4c5ab0d8a346a69245e6123c80db5a",
            "value": 5129
          }
        },
        "bf49daa1bdc64b31bb411b7d73250332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cabb058aad64429ab9b6fc54e029125a",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a5e1c532fe48d28c795ebaa0be490e",
            "value": " 5129/5129 [00:00&lt;00:00, 18107.09 examples/s]"
          }
        },
        "e1d23ca1ca9b49539a8f90363831fb87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559eba48188d4a388b78d687d67cf97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9e71529a0d4906841ca252ba98b734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbfc4f8174944a5385b553506f460f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4c5ab0d8a346a69245e6123c80db5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cabb058aad64429ab9b6fc54e029125a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a5e1c532fe48d28c795ebaa0be490e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral-Finetune: An Introduction!\n",
        "\n",
        "In this notebook, we'll be exploring [`mistral-finetune`](https://github.com/mistralai/mistral-finetune) a tool from Mistral AI that, according to their README.md, enables \"memory-efficient and performant\" fine-tuning of Mistral's models!\n",
        "\n",
        "It leverages LoRA, an industry staple, in order to achieve this goal.\n",
        "\n",
        "Let's dive in and see what Mistral's new tool can do for us!"
      ],
      "metadata": {
        "id": "pqTRDZ4UK1A4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gathering Dependencies\n",
        "\n",
        "First things first, we'll start by gathering the repository, and installing some dependencies!"
      ],
      "metadata": {
        "id": "VwUptndWNi5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP2O1MW9wQgU",
        "outputId": "ff098638-e020-43e3-d5f5-61f0110b9e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mistral-finetune'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 171 (delta 24), reused 14 (delta 14), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (171/171), 135.62 KiB | 746.00 KiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mistralai/mistral-finetune.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mistral-finetune/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3lHJZfgwxkJ",
        "outputId": "553fc48a-e4f6-4762-d316-21703b3f5871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mistral-finetune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qUr requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EX9goIaw0_i",
        "outputId": "69aca649-b567-4946-f66e-69f41e340d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.16.2 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> NOTE: You can safely ignore the dependency conflicts above."
      ],
      "metadata": {
        "id": "nGC6lSGqNw1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Model\n",
        "\n",
        "Next up, we're going to download Mistral 7B v0.3 from Mistral's CDN.\n",
        "\n",
        "> NOTE: You may experience difficulty downloading the model in the Colab environment. Please retry the download if you see your download speeds crash, or you experience a disconnect."
      ],
      "metadata": {
        "id": "VjPtMtTDN1aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byS6Pe94x3tX",
        "outputId": "694de3d0-0fc1-4b01-c215-b04faf014ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-05 15:10:54--  https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar\n",
            "Resolving models.mistralcdn.com (models.mistralcdn.com)... 104.26.7.117, 172.67.70.68, 104.26.6.117, ...\n",
            "Connecting to models.mistralcdn.com (models.mistralcdn.com)|104.26.7.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14496675840 (14G) [application/x-tar]\n",
            "Saving to: ‘mistral-7B-v0.3.tar.1’\n",
            "\n",
            "mistral-7B-v0.3.tar 100%[===================>]  13.50G  46.9MB/s    in 5m 51s  \n",
            "\n",
            "2024-06-05 15:16:46 (39.4 MB/s) - ‘mistral-7B-v0.3.tar.1’ saved [14496675840/14496675840]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to save our model in a directory call `mistral_models` - you can use whatever directory name that you desire - but be sure to change references to `mistral_models` as well!"
      ],
      "metadata": {
        "id": "w4CJ-dZxODFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL=/content/mistral_models && mkdir -p $MODEL && tar -xf mistral-7B-v0.3.tar -C $MODEL"
      ],
      "metadata": {
        "id": "jVs3mY8vx6vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection and Verification\n",
        "\n",
        "Next, we'll want to gather our data and modify it into the appropriate instruct format - as noted in [the repository](https://github.com/mistralai/mistral-finetune?tab=readme-ov-file#instruct).\n",
        "\n",
        "In essence, `mistral-finetune` expects the instruction fine-tuning data to be in the following format:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"messages\" [\n",
        "    {\n",
        "      \"role\" : \"system\",\n",
        "      \"content\" : \"SYSTEM_PROMPT_1\"\n",
        "    },\n",
        "    {\n",
        "      \"role\" : \"user\",\n",
        "      \"content\" : \"USER_PROMPT_1\"\n",
        "    },\n",
        "    {\n",
        "      \"role\" : \"assistant\",\n",
        "      \"content\" : \"RESPONSE_1\"\n",
        "    },\n",
        "  ]\n",
        "}\n",
        "{\n",
        "  \"messages\" [\n",
        "    {\n",
        "      \"role\" : \"system\",\n",
        "      \"content\" : \"SYSTEM_PROMPT_2\"\n",
        "    },\n",
        "    {\n",
        "      \"role\" : \"user\",\n",
        "      \"content\" : \"USER_PROMPT_2\"\n",
        "    },\n",
        "    {\n",
        "      \"role\" : \"assistant\",\n",
        "      \"content\" : \"RESPONSE_2\"\n",
        "    },\n",
        "  ]\n",
        "}\n",
        "...\n",
        "```\n",
        "\n",
        "Notice that the format is `JSONL`!\n",
        "\n",
        "We're going to be leveraging a subset of the [LIMIT: Less Is More for Instruction Tuning](https://www.databricks.com/blog/limit-less-more-instruction-tuning), specifically the `Instruct-v1`, aka `dolly_hhrlhf`!\n",
        "\n",
        "> NOTE: This dataset will require you to accept terms of use - please navigate to [this link](https://huggingface.co/datasets/mosaicml/dolly_hhrlhf) if you havbe not already done so."
      ],
      "metadata": {
        "id": "k-DPUwtqOL0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start with creating a data directory, and popping into it."
      ],
      "metadata": {
        "id": "PZlp7mJgPw-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data"
      ],
      "metadata": {
        "id": "I1FnIY7j-6y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIXV8jJV_BMQ",
        "outputId": "8ee5664c-069a-4a6b-afb8-100479e28517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to grab a few dependencies here for our dataset!"
      ],
      "metadata": {
        "id": "yiSn7GipP6LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU datasets huggingface-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfF9MRvl_rgu",
        "outputId": "96b46322-f311-4b26-b760-f806a218292c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.2/289.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's login to Hugging Face with a READ token."
      ],
      "metadata": {
        "id": "gTKYOBI-QTh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "9a337556c4ef424ea72950d6233f2a5c",
            "3fe8e2b7ec434e148248311814663fef",
            "3bbad9824d5f47b0b20996ad249c1972",
            "4b1fed1b6cd349078813443c822d6d8a",
            "7914978ce0e94af7b7b76e7add58c981",
            "c0dbec7a9a37479b8a0d1b912446cfce",
            "726ca01df0f34e239eb24a0716f578cb",
            "c9e9a7e169b04a8aa2b8e4fd90e87f08",
            "3e0102bd97c64f4ab068a3c98c5848a2",
            "7aa7c64cafdb4158ac710cacf3e303b5",
            "f14695be3b574f88b3e71927cd6caedb",
            "ef05db0ec6664ef3a70fe330e0c12e95",
            "6ef4cda19c074ef9aaa0a051be206d2e",
            "392418d73c79453ebbdbd82a54f481e6",
            "0184fdc8e93548dfa2bd582117322a4e",
            "7590473761494b9eb142e46c4078328e",
            "6e90996d0d754a6faef227188cd58415",
            "97ae6f5070ed450da6a6a471408d4aa6",
            "cf3b28c360b548b88a84373b585c4665",
            "2a7dae5eb00d4b5083177a62bddde1e0",
            "35a0bbed6e574e3889ec80b404fe90af",
            "8f756c08358a4887a53ec0609049e76d",
            "50018394dc3c49e59d1ec740cde58235",
            "953e1e48927641b4907333493cf95fbd",
            "adbf675899cc4b8e93ee4872dd83b505",
            "518d157ac5eb41a4aebc2bab68dc7d20",
            "c32e26fcb2f94c3a852845c2a4916c9b",
            "6cdfb195480242bcb9da574d01a483a6",
            "50ad454fda8f4dc3ba56e4498397b334",
            "6232ce6ba70d4960915991f9a208dea7",
            "7e7dd5b9a90a4cd085a6853802359f20",
            "8079784ed7bf41b1b57ad073a370231e"
          ]
        },
        "id": "2PHevtT1_3Mw",
        "outputId": "517f4828-c13f-4499-b3e8-6519d2bc10da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a337556c4ef424ea72950d6233f2a5c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can download our data!"
      ],
      "metadata": {
        "id": "IsEgVGwdSGuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"mosaicml/dolly_hhrlhf\")"
      ],
      "metadata": {
        "id": "nH0AiRBl_D5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a peak at our dataset to see what kind of shape it's in!"
      ],
      "metadata": {
        "id": "7DeeydDHSRmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXe3_NbtAR7B",
        "outputId": "a626b51d-28ec-4326-9fc0-ed7a1f8cb616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'response'],\n",
              "        num_rows: 59310\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['prompt', 'response'],\n",
              "        num_rows: 5129\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10abs_reSO9s",
        "outputId": "168b865d-c1d8-46ed-884f-52f9e5d5940c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nwhat is kangen water?\\n\\n### Response:\\n',\n",
              " 'response': 'Kangen water is alkaline ionized water produced through a process called electrolysis.  Kangen water is also referred to electrolyzed reduced water.  This water is characterized by an large negative oxidation reduction potential and a potential hydrogen level > 7.0 making the water alkaline.  It is also infused with molecular hydrogen in the amount of 1 - 1.5 parts per million per gallon of water produced.  This infused hydrogen has been shown to be a very good anti-inflammatory for the body.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, this is not the expected format - so we'll need to do some formatting to make sure our data is in the expected format.\n",
        "\n",
        "We can do this with `dataset.map()`, which simple need to create a formatting function."
      ],
      "metadata": {
        "id": "fFHJv5P_SVLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mistral_finetune_format(sample):\n",
        "  system_prompt = sample[\"prompt\"].split(\"### Instruction:\")[0].strip().lstrip()\n",
        "  user_prompt = sample[\"prompt\"].split(\"### Instruction:\")[-1].split(\"### Response:\")[0].strip().lstrip()\n",
        "\n",
        "  return {\"data\" : {\"messages\" : [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}, {\"role\" : \"assistant\", \"content\" : sample[\"response\"]}]}}"
      ],
      "metadata": {
        "id": "ozw9xLSTABYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify our formatting function worked!"
      ],
      "metadata": {
        "id": "sDPp2YQUSryF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_finetune_format(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2GPppA4Sk4-",
        "outputId": "8e2b66f3-bd52-43e9-aa4f-550d3d8d0d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': {'messages': [{'role': 'system',\n",
              "    'content': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.'},\n",
              "   {'role': 'user', 'content': 'what is kangen water?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Kangen water is alkaline ionized water produced through a process called electrolysis.  Kangen water is also referred to electrolyzed reduced water.  This water is characterized by an large negative oxidation reduction potential and a potential hydrogen level > 7.0 making the water alkaline.  It is also infused with molecular hydrogen in the amount of 1 - 1.5 parts per million per gallon of water produced.  This infused hydrogen has been shown to be a very good anti-inflammatory for the body.'}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data formatter is tested - lets map it across the entire dataset!"
      ],
      "metadata": {
        "id": "g2LExxFDSh28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(mistral_finetune_format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "91e1a95311b643929184e8f8b38272b5",
            "f69063ac618d4173bffcaa34947bd22c",
            "8db7bc57008943f4b9c37e39ddb52946",
            "83248c52c8cc4e6f81c3db2691e549c5",
            "4b62a6eee2404dbfa625041a0740ed30",
            "386a5dc1c4904dc7a5d0a27a6f4157d0",
            "afb9efafbdac429492c0513f36b64d02",
            "7b54fce84d2448d28852c378d87954f3",
            "380bec7c43844ac29ebc983bf570e901",
            "7a0a9953413540cc94b2242174e991ca",
            "2795de2d4b86494694446770ed648ab6",
            "af4d1871474f45c1a38bd68e6ffe8c88",
            "2a78d148b19f41b98b131b65a2fd80af",
            "41eac013db7c4a0e94dde0e371debeb0",
            "bf49daa1bdc64b31bb411b7d73250332",
            "e1d23ca1ca9b49539a8f90363831fb87",
            "559eba48188d4a388b78d687d67cf97d",
            "1d9e71529a0d4906841ca252ba98b734",
            "cbfc4f8174944a5385b553506f460f93",
            "7b4c5ab0d8a346a69245e6123c80db5a",
            "cabb058aad64429ab9b6fc54e029125a",
            "c8a5e1c532fe48d28c795ebaa0be490e"
          ]
        },
        "id": "PMbNhCLpCj_g",
        "outputId": "ba4ee24b-1a51-400e-a4bb-90c3cff89a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/59310 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91e1a95311b643929184e8f8b38272b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5129 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af4d1871474f45c1a38bd68e6ffe8c88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4miC7KXTYnX",
        "outputId": "3ceba016-1d9a-41e0-e622-12b66fa81f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'response', 'data'],\n",
              "        num_rows: 59310\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['prompt', 'response', 'data'],\n",
              "        num_rows: 5129\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save our data as a `JSONL` file for compatibility!\n",
        "\n",
        "We'll create a training set, and a evaluation set."
      ],
      "metadata": {
        "id": "gRfnYJjQS2dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = \"/content/data/train_instruct.jsonl\"\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "  for item in formatted_dataset[\"train\"][\"data\"]:\n",
        "    json_str = json.dumps(item)\n",
        "    file.write(json_str + \"\\n\")"
      ],
      "metadata": {
        "id": "tkjT2a76CuSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/data/test_instruct.jsonl\"\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "  for item in formatted_dataset[\"test\"][\"data\"]:\n",
        "    json_str = json.dumps(item)\n",
        "    file.write(json_str + \"\\n\")"
      ],
      "metadata": {
        "id": "k5AramiBDdU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verifying the Dataset\n",
        "\n",
        "We can use the provided tools to verify that our dataset is in the correct shape - let's first pass our dataset through the reformat to clean up, or skip, any potential issues!"
      ],
      "metadata": {
        "id": "fvDq6xsnTHri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m utils.reformat_data /content/data/train_instruct.jsonl"
      ],
      "metadata": {
        "id": "ROQOPaq1BDRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m utils.reformat_data /content/data/test_instruct.jsonl"
      ],
      "metadata": {
        "id": "8TaXXHhpBKIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our reformat completed with no issues - we can move to validating our data - but before we do, we need to talk about the `.yaml` file that acts as a guide for our training process.\n",
        "\n",
        "Let's make it together in the following cell - we'll start by adding referene to our data.\n",
        "\n",
        "Notice that our data is under the `data` header."
      ],
      "metadata": {
        "id": "-hnnf1EKU1Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_path = \"/content/data/train_instruct.jsonl\"\n",
        "eval_dataset_path = \"/content/data/test_instruct.jsonl\"\n",
        "\n",
        "training_yaml = f\"\"\"\\\n",
        "data:\n",
        "  instruct_data: '{training_dataset_path}'\n",
        "  eval_instruct_data: '{eval_dataset_path}'\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UTC0_r9AVCXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll add a reference to our downloaded and extracted model!"
      ],
      "metadata": {
        "id": "RMgu4XnJVyse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/mistral_models\"\n",
        "\n",
        "training_yaml += f\"\\nmodel_id_or_path: '{model_path}'\""
      ],
      "metadata": {
        "id": "LA51XFJaV23y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can add some additional training parameters.\n",
        "\n",
        "These are typical, and similar to what you'd see in something like `transformers` from Hugging Face!"
      ],
      "metadata": {
        "id": "fXgSeaE-WbXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LORA_RANK = 64\n",
        "SEQ_LEN = 4092\n",
        "BATCH_SIZE = 1\n",
        "NUM_MICROBATCHES = 8\n",
        "MAX_STEPS = 300\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 0.1\n",
        "\n",
        "OUTPUT_DIR = \"content/limit_test\""
      ],
      "metadata": {
        "id": "4DmMr9ZzX9cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_yaml += f\"\"\"\n",
        "# optim\n",
        "seq_len: {SEQ_LEN}\n",
        "batch_size: {BATCH_SIZE}\n",
        "num_microbatches: {NUM_MICROBATCHES}\n",
        "max_steps: {MAX_STEPS}\n",
        "\n",
        "optim:\n",
        "  lr: {LEARNING_RATE}\n",
        "  weight_decay: {WEIGHT_DECAY}\n",
        "  pct_start: 0.05\n",
        "\n",
        "# other\n",
        "seed: 0\n",
        "log_freq: 1\n",
        "eval_freq: 100\n",
        "no_eval: False\n",
        "ckpt_freq: 100\n",
        "\n",
        "save_adapters: True\n",
        "\n",
        "run_dir: '{OUTPUT_DIR}'\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SSQB5D7-WkKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights and Biases Integration\n",
        "\n",
        "Now we can add references to our Weights and Biases project, API key, and run name!\n",
        "\n",
        "This integration is straightforward and lets us monitor our fine-tuning very easily!"
      ],
      "metadata": {
        "id": "v9soNgQVXdJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU wandb"
      ],
      "metadata": {
        "id": "JHUyBzI9XoQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can add these Weights and Biases configurations to our `.yaml` file!"
      ],
      "metadata": {
        "id": "EZp3ki4PXqJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "WANDB_PROJECT = \"MistralFinetune\"\n",
        "WANBD_RUN_NAME = \"DollyInstruct\"\n",
        "API_KEY = getpass.getpass(\"WandB API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85eT9AdWYJpb",
        "outputId": "9d12e70f-5aea-421d-bacc-568902a1a08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WandB API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_yaml += f\"\"\"\n",
        "wandb:\n",
        "  project: '{WANDB_PROJECT}'\n",
        "  run_name: '{WANBD_RUN_NAME}'\n",
        "  key: '{API_KEY}'\n",
        "  offline: False\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "z2mH9z3_YEF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's save our our `.yaml` file and use it to validate our data!"
      ],
      "metadata": {
        "id": "7esRwGXVZXZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open('/content/instruct_tune_mistral_7B.yaml', 'w') as file:\n",
        "    yaml.dump(yaml.safe_load(training_yaml), file)"
      ],
      "metadata": {
        "id": "tGzWJo4VZcTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m utils.validate_data --train_yaml /content/instruct_tune_mistral_7B.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMliwetLBOoW",
        "outputId": "ae679b18-e1d5-41cf-b8e1-405faadc06d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]Validating /content/data/train_instruct.jsonl ...\n",
            "\n",
            "  0% 0/59310 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 128/59310 [00:00<00:46, 1277.78it/s]\u001b[A\n",
            "  0% 286/59310 [00:00<00:40, 1452.69it/s]\u001b[A\n",
            "  1% 432/59310 [00:00<00:40, 1451.90it/s]\u001b[A\n",
            "  1% 578/59310 [00:00<00:42, 1396.78it/s]\u001b[A\n",
            "  1% 743/59310 [00:00<00:39, 1484.30it/s]\u001b[A\n",
            "  2% 892/59310 [00:00<00:39, 1484.37it/s]\u001b[A\n",
            "  2% 1052/59310 [00:00<00:38, 1519.21it/s]\u001b[A\n",
            "  2% 1223/59310 [00:00<00:37, 1552.61it/s]\u001b[A\n",
            "  2% 1379/59310 [00:00<00:37, 1541.97it/s]\u001b[A\n",
            "  3% 1534/59310 [00:01<00:38, 1499.33it/s]\u001b[A\n",
            "  3% 1705/59310 [00:01<00:36, 1561.28it/s]\u001b[A\n",
            "  3% 1862/59310 [00:01<00:37, 1547.57it/s]\u001b[A\n",
            "  3% 2018/59310 [00:01<00:39, 1466.52it/s]\u001b[A\n",
            "  4% 2166/59310 [00:01<00:41, 1387.80it/s]\u001b[A\n",
            "  4% 2320/59310 [00:01<00:39, 1429.32it/s]\u001b[A\n",
            "  4% 2465/59310 [00:01<00:40, 1410.41it/s]\u001b[A\n",
            "  4% 2607/59310 [00:01<00:40, 1405.32it/s]\u001b[A\n",
            "  5% 2770/59310 [00:01<00:38, 1468.58it/s]\u001b[A\n",
            "  5% 2921/59310 [00:01<00:38, 1478.15it/s]\u001b[A\n",
            "  5% 3070/59310 [00:02<00:38, 1458.02it/s]\u001b[A\n",
            "  5% 3217/59310 [00:02<00:42, 1331.04it/s]\u001b[A\n",
            "  6% 3357/59310 [00:02<00:41, 1349.56it/s]\u001b[A\n",
            "  6% 3494/59310 [00:02<00:41, 1351.52it/s]\u001b[A\n",
            "  6% 3644/59310 [00:02<00:39, 1392.98it/s]\u001b[A\n",
            "  6% 3785/59310 [00:02<00:40, 1379.65it/s]\u001b[A\n",
            "  7% 3937/59310 [00:02<00:39, 1416.20it/s]\u001b[A\n",
            "  7% 4080/59310 [00:02<00:42, 1294.68it/s]\u001b[A\n",
            "  7% 4239/59310 [00:02<00:40, 1372.57it/s]\u001b[A\n",
            "  7% 4379/59310 [00:03<00:42, 1300.14it/s]\u001b[A\n",
            "  8% 4529/59310 [00:03<00:40, 1352.63it/s]\u001b[A\n",
            "  8% 4688/59310 [00:03<00:38, 1411.34it/s]\u001b[A\n",
            "  8% 4831/59310 [00:03<00:39, 1386.99it/s]\u001b[A\n",
            "  8% 4971/59310 [00:03<00:39, 1387.03it/s]\u001b[A\n",
            "  9% 5121/59310 [00:03<00:38, 1417.51it/s]\u001b[A\n",
            "  9% 5264/59310 [00:03<00:39, 1385.06it/s]\u001b[A\n",
            "  9% 5404/59310 [00:03<00:39, 1366.11it/s]\u001b[A\n",
            "  9% 5545/59310 [00:03<00:39, 1377.29it/s]\u001b[A\n",
            " 10% 5697/59310 [00:04<00:37, 1417.22it/s]\u001b[A\n",
            " 10% 5860/59310 [00:04<00:36, 1476.21it/s]\u001b[A\n",
            " 10% 6028/59310 [00:04<00:34, 1532.39it/s]\u001b[A\n",
            " 10% 6187/59310 [00:04<00:34, 1549.18it/s]\u001b[A\n",
            " 11% 6344/59310 [00:04<00:34, 1554.03it/s]\u001b[A\n",
            " 11% 6500/59310 [00:04<00:34, 1539.24it/s]\u001b[A\n",
            " 11% 6655/59310 [00:04<00:35, 1488.75it/s]\u001b[A\n",
            " 11% 6805/59310 [00:04<00:36, 1446.92it/s]\u001b[A\n",
            " 12% 6951/59310 [00:04<00:36, 1439.21it/s]\u001b[A\n",
            " 12% 7096/59310 [00:04<00:36, 1426.44it/s]\u001b[A\n",
            " 12% 7257/59310 [00:05<00:35, 1476.27it/s]\u001b[A\n",
            " 13% 7418/59310 [00:05<00:34, 1510.65it/s]\u001b[A\n",
            " 13% 7570/59310 [00:05<00:36, 1428.08it/s]\u001b[A\n",
            " 13% 7739/59310 [00:05<00:34, 1494.00it/s]\u001b[A\n",
            " 13% 7890/59310 [00:05<00:34, 1485.58it/s]\u001b[A\n",
            " 14% 8053/59310 [00:05<00:33, 1526.25it/s]\u001b[A\n",
            " 14% 8207/59310 [00:05<00:33, 1522.84it/s]\u001b[A\n",
            " 14% 8384/59310 [00:05<00:31, 1594.81it/s]\u001b[A\n",
            " 14% 8544/59310 [00:05<00:32, 1560.86it/s]\u001b[A\n",
            " 15% 8701/59310 [00:05<00:32, 1555.36it/s]\u001b[A\n",
            " 15% 8857/59310 [00:06<00:33, 1519.74it/s]\u001b[A\n",
            " 15% 9023/59310 [00:06<00:32, 1544.33it/s]\u001b[A\n",
            " 15% 9178/59310 [00:06<00:34, 1456.50it/s]\u001b[A\n",
            " 16% 9325/59310 [00:06<00:35, 1399.73it/s]\u001b[A\n",
            " 16% 9471/59310 [00:06<00:35, 1411.52it/s]\u001b[A\n",
            " 16% 9617/59310 [00:06<00:34, 1425.08it/s]\u001b[A\n",
            " 16% 9772/59310 [00:06<00:33, 1459.93it/s]\u001b[A\n",
            " 17% 9919/59310 [00:06<00:34, 1438.28it/s]\u001b[A\n",
            " 17% 10064/59310 [00:06<00:34, 1413.89it/s]\u001b[A\n",
            " 17% 10206/59310 [00:07<00:35, 1398.58it/s]\u001b[A\n",
            " 17% 10347/59310 [00:07<00:36, 1359.58it/s]\u001b[A\n",
            " 18% 10496/59310 [00:07<00:34, 1394.99it/s]\u001b[A\n",
            " 18% 10647/59310 [00:07<00:34, 1428.17it/s]\u001b[A\n",
            " 18% 10799/59310 [00:07<00:33, 1454.43it/s]\u001b[A\n",
            " 18% 10945/59310 [00:07<00:34, 1403.13it/s]\u001b[A\n",
            " 19% 11086/59310 [00:07<00:34, 1398.18it/s]\u001b[A\n",
            " 19% 11246/59310 [00:07<00:32, 1456.54it/s]\u001b[A\n",
            " 19% 11394/59310 [00:07<00:32, 1457.78it/s]\u001b[A\n",
            " 19% 11541/59310 [00:07<00:33, 1431.83it/s]\u001b[A\n",
            " 20% 11694/59310 [00:08<00:32, 1459.47it/s]\u001b[A\n",
            " 20% 11841/59310 [00:08<00:33, 1415.34it/s]\u001b[A\n",
            " 20% 11990/59310 [00:08<00:32, 1435.31it/s]\u001b[A\n",
            " 20% 12134/59310 [00:08<00:32, 1434.74it/s]\u001b[A\n",
            " 21% 12278/59310 [00:08<00:34, 1369.23it/s]\u001b[A\n",
            " 21% 12419/59310 [00:08<00:33, 1380.44it/s]\u001b[A\n",
            " 21% 12576/59310 [00:08<00:32, 1433.93it/s]\u001b[A\n",
            " 21% 12722/59310 [00:08<00:32, 1438.22it/s]\u001b[A\n",
            " 22% 12902/59310 [00:08<00:30, 1542.81it/s]\u001b[A\n",
            " 22% 13057/59310 [00:09<00:30, 1524.31it/s]\u001b[A\n",
            " 22% 13210/59310 [00:09<00:31, 1460.28it/s]\u001b[A\n",
            " 23% 13357/59310 [00:09<00:32, 1425.13it/s]\u001b[A\n",
            " 23% 13507/59310 [00:09<00:31, 1446.02it/s]\u001b[A\n",
            " 23% 13653/59310 [00:09<00:31, 1439.70it/s]\u001b[A\n",
            " 23% 13806/59310 [00:09<00:31, 1465.66it/s]\u001b[A\n",
            " 24% 13953/59310 [00:09<00:31, 1441.77it/s]\u001b[A\n",
            " 24% 14098/59310 [00:09<00:32, 1383.36it/s]\u001b[A\n",
            " 24% 14237/59310 [00:09<00:32, 1382.06it/s]\u001b[A\n",
            " 24% 14376/59310 [00:09<00:33, 1333.59it/s]\u001b[A\n",
            " 25% 14542/59310 [00:10<00:31, 1425.08it/s]\u001b[A\n",
            " 25% 14688/59310 [00:10<00:31, 1435.08it/s]\u001b[A\n",
            " 25% 14833/59310 [00:10<00:31, 1417.73it/s]\u001b[A\n",
            " 25% 15014/59310 [00:10<00:28, 1531.60it/s]\u001b[A\n",
            " 26% 15225/59310 [00:10<00:25, 1699.04it/s]\u001b[A\n",
            " 26% 15431/59310 [00:10<00:24, 1803.07it/s]\u001b[A\n",
            " 26% 15641/59310 [00:10<00:23, 1889.66it/s]\u001b[A\n",
            " 27% 15851/59310 [00:10<00:22, 1952.09it/s]\u001b[A\n",
            " 27% 16047/59310 [00:10<00:22, 1911.68it/s]\u001b[A\n",
            " 27% 16252/59310 [00:11<00:22, 1951.41it/s]\u001b[A\n",
            " 28% 16448/59310 [00:11<00:22, 1942.10it/s]\u001b[A\n",
            " 28% 16650/59310 [00:11<00:21, 1964.99it/s]\u001b[A\n",
            " 28% 16866/59310 [00:11<00:21, 2020.88it/s]\u001b[A\n",
            " 29% 17073/59310 [00:11<00:20, 2034.52it/s]\u001b[A\n",
            " 29% 17286/59310 [00:11<00:20, 2062.88it/s]\u001b[A\n",
            " 29% 17493/59310 [00:11<00:20, 2036.50it/s]\u001b[A\n",
            " 30% 17703/59310 [00:11<00:20, 2054.73it/s]\u001b[A\n",
            " 30% 17921/59310 [00:11<00:19, 2089.95it/s]\u001b[A\n",
            " 31% 18131/59310 [00:11<00:20, 2019.61it/s]\u001b[A\n",
            " 31% 18334/59310 [00:12<00:20, 1978.71it/s]\u001b[A\n",
            " 31% 18533/59310 [00:12<00:20, 1969.97it/s]\u001b[A\n",
            " 32% 18731/59310 [00:12<00:20, 1954.19it/s]\u001b[A\n",
            " 32% 18927/59310 [00:12<00:21, 1917.77it/s]\u001b[A\n",
            " 32% 19129/59310 [00:12<00:20, 1944.96it/s]\u001b[A\n",
            " 33% 19336/59310 [00:12<00:20, 1977.66it/s]\u001b[A\n",
            " 33% 19544/59310 [00:12<00:19, 2007.53it/s]\u001b[A\n",
            " 33% 19754/59310 [00:12<00:19, 2034.02it/s]\u001b[A\n",
            " 34% 19958/59310 [00:12<00:19, 2020.92it/s]\u001b[A\n",
            " 34% 20165/59310 [00:12<00:19, 2034.30it/s]\u001b[A\n",
            " 34% 20369/59310 [00:13<00:19, 2032.13it/s]\u001b[A\n",
            " 35% 20573/59310 [00:13<00:19, 2010.70it/s]\u001b[A\n",
            " 35% 20785/59310 [00:13<00:18, 2042.55it/s]\u001b[A\n",
            " 35% 20995/59310 [00:13<00:18, 2059.53it/s]\u001b[A\n",
            " 36% 21202/59310 [00:13<00:18, 2024.77it/s]\u001b[A\n",
            " 36% 21405/59310 [00:13<00:18, 2017.15it/s]\u001b[A\n",
            " 36% 21612/59310 [00:13<00:18, 2031.58it/s]\u001b[A\n",
            " 37% 21823/59310 [00:13<00:18, 2053.96it/s]\u001b[A\n",
            " 37% 22029/59310 [00:13<00:18, 2037.45it/s]\u001b[A\n",
            " 37% 22233/59310 [00:13<00:18, 2005.34it/s]\u001b[A\n",
            " 38% 22448/59310 [00:14<00:18, 2047.83it/s]\u001b[A\n",
            " 38% 22653/59310 [00:14<00:18, 2036.45it/s]\u001b[A\n",
            " 39% 22868/59310 [00:14<00:17, 2063.99it/s]\u001b[A\n",
            " 39% 23075/59310 [00:14<00:17, 2042.12it/s]\u001b[A\n",
            " 39% 23288/59310 [00:14<00:17, 2066.11it/s]\u001b[A\n",
            " 40% 23496/59310 [00:14<00:17, 2068.24it/s]\u001b[A\n",
            " 40% 23703/59310 [00:14<00:17, 2040.36it/s]\u001b[A\n",
            " 40% 23920/59310 [00:14<00:17, 2075.95it/s]\u001b[A\n",
            " 41% 24132/59310 [00:14<00:16, 2087.24it/s]\u001b[A\n",
            " 41% 24346/59310 [00:14<00:16, 2102.12it/s]\u001b[A\n",
            " 41% 24557/59310 [00:15<00:16, 2076.48it/s]\u001b[A\n",
            " 42% 24765/59310 [00:15<00:16, 2061.87it/s]\u001b[A\n",
            " 42% 24972/59310 [00:15<00:16, 2054.15it/s]\u001b[A\n",
            " 42% 25179/59310 [00:15<00:16, 2055.61it/s]\u001b[A\n",
            " 43% 25385/59310 [00:15<00:16, 2051.51it/s]\u001b[A\n",
            " 43% 25598/59310 [00:15<00:16, 2073.46it/s]\u001b[A\n",
            " 44% 25806/59310 [00:15<00:16, 2016.32it/s]\u001b[A\n",
            " 44% 26026/59310 [00:15<00:16, 2069.37it/s]\u001b[A\n",
            " 44% 26234/59310 [00:15<00:16, 2056.15it/s]\u001b[A\n",
            " 45% 26447/59310 [00:16<00:15, 2074.74it/s]\u001b[A\n",
            " 45% 26655/59310 [00:16<00:15, 2061.45it/s]\u001b[A\n",
            " 45% 26868/59310 [00:16<00:15, 2078.91it/s]\u001b[A\n",
            " 46% 27077/59310 [00:16<00:15, 2071.32it/s]\u001b[A\n",
            " 46% 27285/59310 [00:16<00:15, 2060.34it/s]\u001b[A\n",
            " 46% 27492/59310 [00:16<00:15, 2053.23it/s]\u001b[A\n",
            " 47% 27698/59310 [00:16<00:15, 2051.42it/s]\u001b[A\n",
            " 47% 27904/59310 [00:16<00:15, 2039.91it/s]\u001b[A\n",
            " 47% 28120/59310 [00:16<00:15, 2074.70it/s]\u001b[A\n",
            " 48% 28332/59310 [00:16<00:14, 2086.76it/s]\u001b[A\n",
            " 48% 28541/59310 [00:17<00:14, 2074.00it/s]\u001b[A\n",
            " 48% 28749/59310 [00:17<00:14, 2057.41it/s]\u001b[A\n",
            " 49% 28955/59310 [00:17<00:15, 2010.56it/s]\u001b[A\n",
            " 49% 29157/59310 [00:17<00:15, 2003.66it/s]\u001b[A\n",
            " 50% 29363/59310 [00:17<00:14, 2019.03it/s]\u001b[A\n",
            " 50% 29566/59310 [00:17<00:14, 2013.01it/s]\u001b[A\n",
            " 50% 29768/59310 [00:17<00:14, 2004.10it/s]\u001b[A\n",
            " 51% 29989/59310 [00:17<00:14, 2063.74it/s]\u001b[A\n",
            " 51% 30196/59310 [00:17<00:14, 2022.49it/s]\u001b[A\n",
            " 51% 30399/59310 [00:17<00:14, 1994.31it/s]\u001b[A\n",
            " 52% 30599/59310 [00:18<00:14, 1971.03it/s]\u001b[A\n",
            " 52% 30803/59310 [00:18<00:14, 1987.43it/s]\u001b[A\n",
            " 52% 31002/59310 [00:18<00:14, 1975.74it/s]\u001b[A\n",
            " 53% 31210/59310 [00:18<00:14, 2005.67it/s]\u001b[A\n",
            " 53% 31411/59310 [00:18<00:13, 2006.60it/s]\u001b[A\n",
            " 53% 31614/59310 [00:18<00:13, 2012.07it/s]\u001b[A\n",
            " 54% 31828/59310 [00:18<00:13, 2049.18it/s]\u001b[A\n",
            " 54% 32033/59310 [00:18<00:13, 2006.45it/s]\u001b[A\n",
            " 54% 32246/59310 [00:18<00:13, 2041.19it/s]\u001b[A\n",
            " 55% 32454/59310 [00:18<00:13, 2052.56it/s]\u001b[A\n",
            " 55% 32669/59310 [00:19<00:12, 2080.72it/s]\u001b[A\n",
            " 55% 32878/59310 [00:19<00:13, 2029.92it/s]\u001b[A\n",
            " 56% 33098/59310 [00:19<00:12, 2077.77it/s]\u001b[A\n",
            " 56% 33307/59310 [00:19<00:12, 2076.84it/s]\u001b[A\n",
            " 57% 33518/59310 [00:19<00:12, 2065.84it/s]\u001b[A\n",
            " 57% 33725/59310 [00:19<00:12, 1991.70it/s]\u001b[A\n",
            " 57% 33925/59310 [00:19<00:12, 1991.74it/s]\u001b[A\n",
            " 58% 34136/59310 [00:19<00:12, 2024.53it/s]\u001b[A\n",
            " 58% 34339/59310 [00:19<00:12, 1992.33it/s]\u001b[A\n",
            " 58% 34539/59310 [00:19<00:12, 1988.64it/s]\u001b[A\n",
            " 59% 34746/59310 [00:20<00:12, 2012.47it/s]\u001b[A\n",
            " 59% 34963/59310 [00:20<00:11, 2055.06it/s]\u001b[A\n",
            " 59% 35169/59310 [00:20<00:11, 2017.75it/s]\u001b[A\n",
            " 60% 35377/59310 [00:20<00:11, 2034.72it/s]\u001b[A\n",
            " 60% 35581/59310 [00:20<00:12, 1959.80it/s]\u001b[A\n",
            " 60% 35778/59310 [00:20<00:12, 1939.56it/s]\u001b[A\n",
            " 61% 35989/59310 [00:20<00:11, 1987.68it/s]\u001b[A\n",
            " 61% 36196/59310 [00:20<00:11, 2010.71it/s]\u001b[A\n",
            " 61% 36398/59310 [00:20<00:11, 1990.15it/s]\u001b[A\n",
            " 62% 36599/59310 [00:21<00:11, 1994.55it/s]\u001b[A\n",
            " 62% 36810/59310 [00:21<00:11, 2028.29it/s]\u001b[A\n",
            " 62% 37014/59310 [00:21<00:11, 1971.71it/s]\u001b[A\n",
            " 63% 37212/59310 [00:21<00:11, 1932.30it/s]\u001b[A\n",
            " 63% 37406/59310 [00:21<00:11, 1876.15it/s]\u001b[A\n",
            " 63% 37620/59310 [00:21<00:11, 1951.43it/s]\u001b[A\n",
            " 64% 37816/59310 [00:21<00:11, 1950.28it/s]\u001b[A\n",
            " 64% 38012/59310 [00:21<00:11, 1929.62it/s]\u001b[A\n",
            " 64% 38206/59310 [00:21<00:11, 1892.54it/s]\u001b[A\n",
            " 65% 38411/59310 [00:21<00:10, 1937.40it/s]\u001b[A\n",
            " 65% 38606/59310 [00:22<00:10, 1923.97it/s]\u001b[A\n",
            " 65% 38799/59310 [00:22<00:10, 1910.17it/s]\u001b[A\n",
            " 66% 38996/59310 [00:22<00:10, 1926.39it/s]\u001b[A\n",
            " 66% 39205/59310 [00:22<00:10, 1973.91it/s]\u001b[A\n",
            " 66% 39403/59310 [00:22<00:10, 1941.97it/s]\u001b[A\n",
            " 67% 39602/59310 [00:22<00:10, 1955.85it/s]\u001b[A\n",
            " 67% 39798/59310 [00:22<00:10, 1922.96it/s]\u001b[A\n",
            " 67% 40009/59310 [00:22<00:09, 1954.94it/s]\u001b[A\n",
            " 68% 40213/59310 [00:22<00:09, 1978.05it/s]\u001b[A\n",
            " 68% 40411/59310 [00:22<00:09, 1943.81it/s]\u001b[A\n",
            " 68% 40606/59310 [00:23<00:09, 1941.74it/s]\u001b[A\n",
            " 69% 40820/59310 [00:23<00:09, 1996.73it/s]\u001b[A\n",
            " 69% 41041/59310 [00:23<00:08, 2058.94it/s]\u001b[A\n",
            " 70% 41251/59310 [00:23<00:08, 2069.95it/s]\u001b[A\n",
            " 70% 41459/59310 [00:23<00:08, 2070.37it/s]\u001b[A\n",
            " 70% 41667/59310 [00:23<00:08, 2044.15it/s]\u001b[A\n",
            " 71% 41872/59310 [00:23<00:08, 2035.30it/s]\u001b[A\n",
            " 71% 42076/59310 [00:23<00:08, 2029.64it/s]\u001b[A\n",
            " 71% 42295/59310 [00:23<00:08, 2074.58it/s]\u001b[A\n",
            " 72% 42503/59310 [00:24<00:08, 2044.24it/s]\u001b[A\n",
            " 72% 42713/59310 [00:24<00:08, 2060.27it/s]\u001b[A\n",
            " 72% 42925/59310 [00:24<00:07, 2072.99it/s]\u001b[A\n",
            " 73% 43137/59310 [00:24<00:07, 2085.74it/s]\u001b[A\n",
            " 73% 43346/59310 [00:24<00:07, 2046.83it/s]\u001b[A\n",
            " 73% 43551/59310 [00:24<00:07, 2009.37it/s]\u001b[A\n",
            " 74% 43753/59310 [00:24<00:07, 1992.42it/s]\u001b[A\n",
            " 74% 43953/59310 [00:24<00:07, 1976.15it/s]\u001b[A\n",
            " 74% 44163/59310 [00:24<00:07, 2008.64it/s]\u001b[A\n",
            " 75% 44373/59310 [00:24<00:07, 2035.44it/s]\u001b[A\n",
            " 75% 44577/59310 [00:25<00:07, 2015.41it/s]\u001b[A\n",
            " 75% 44779/59310 [00:25<00:07, 2015.78it/s]\u001b[A\n",
            " 76% 44981/59310 [00:25<00:07, 2010.98it/s]\u001b[A\n",
            " 76% 45198/59310 [00:25<00:06, 2057.90it/s]\u001b[A\n",
            " 77% 45407/59310 [00:25<00:06, 2067.27it/s]\u001b[A\n",
            " 77% 45614/59310 [00:25<00:06, 1976.34it/s]\u001b[A\n",
            " 77% 45823/59310 [00:25<00:06, 2007.21it/s]\u001b[A\n",
            " 78% 46025/59310 [00:25<00:06, 1988.18it/s]\u001b[A\n",
            " 78% 46225/59310 [00:25<00:06, 1983.07it/s]\u001b[A\n",
            " 78% 46424/59310 [00:25<00:06, 1960.98it/s]\u001b[A\n",
            " 79% 46621/59310 [00:26<00:06, 1929.52it/s]\u001b[A\n",
            " 79% 46820/59310 [00:26<00:06, 1945.98it/s]\u001b[A\n",
            " 79% 47026/59310 [00:26<00:06, 1976.70it/s]\u001b[A\n",
            " 80% 47225/59310 [00:26<00:06, 1977.57it/s]\u001b[A\n",
            " 80% 47428/59310 [00:26<00:05, 1990.89it/s]\u001b[A\n",
            " 80% 47628/59310 [00:26<00:05, 1971.12it/s]\u001b[A\n",
            " 81% 47832/59310 [00:26<00:05, 1990.13it/s]\u001b[A\n",
            " 81% 48037/59310 [00:26<00:05, 2005.91it/s]\u001b[A\n",
            " 81% 48238/59310 [00:26<00:05, 1975.12it/s]\u001b[A\n",
            " 82% 48451/59310 [00:26<00:05, 2016.26it/s]\u001b[A\n",
            " 82% 48666/59310 [00:27<00:05, 2055.47it/s]\u001b[A\n",
            " 82% 48872/59310 [00:27<00:05, 2047.83it/s]\u001b[A\n",
            " 83% 49088/59310 [00:27<00:04, 2076.84it/s]\u001b[A\n",
            " 83% 49297/59310 [00:27<00:04, 2079.91it/s]\u001b[A\n",
            " 83% 49512/59310 [00:27<00:04, 2097.94it/s]\u001b[A\n",
            " 84% 49723/59310 [00:27<00:04, 2100.28it/s]\u001b[A\n",
            " 84% 49934/59310 [00:27<00:04, 2060.70it/s]\u001b[A\n",
            " 85% 50145/59310 [00:27<00:04, 2072.22it/s]\u001b[A\n",
            " 85% 50353/59310 [00:27<00:04, 2045.08it/s]\u001b[A\n",
            " 85% 50558/59310 [00:27<00:04, 2034.57it/s]\u001b[A\n",
            " 86% 50762/59310 [00:28<00:04, 2020.69it/s]\u001b[A\n",
            " 86% 50967/59310 [00:28<00:04, 2026.98it/s]\u001b[A\n",
            " 86% 51180/59310 [00:28<00:03, 2054.85it/s]\u001b[A\n",
            " 87% 51386/59310 [00:28<00:03, 2027.79it/s]\u001b[A\n",
            " 87% 51594/59310 [00:28<00:03, 2042.88it/s]\u001b[A\n",
            " 87% 51799/59310 [00:28<00:03, 2035.36it/s]\u001b[A\n",
            " 88% 52012/59310 [00:28<00:03, 2062.05it/s]\u001b[A\n",
            " 88% 52219/59310 [00:28<00:03, 2062.35it/s]\u001b[A\n",
            " 88% 52426/59310 [00:28<00:03, 2044.76it/s]\u001b[A\n",
            " 89% 52646/59310 [00:29<00:03, 2089.54it/s]\u001b[A\n",
            " 89% 52860/59310 [00:29<00:03, 2100.23it/s]\u001b[A\n",
            " 89% 53071/59310 [00:29<00:02, 2100.24it/s]\u001b[A\n",
            " 90% 53282/59310 [00:29<00:02, 2092.44it/s]\u001b[A\n",
            " 90% 53492/59310 [00:29<00:02, 2061.12it/s]\u001b[A\n",
            " 91% 53701/59310 [00:29<00:02, 2068.25it/s]\u001b[A\n",
            " 91% 53910/59310 [00:29<00:02, 2070.35it/s]\u001b[A\n",
            " 91% 54118/59310 [00:29<00:02, 2042.83it/s]\u001b[A\n",
            " 92% 54323/59310 [00:29<00:02, 2029.08it/s]\u001b[A\n",
            " 92% 54532/59310 [00:29<00:02, 2044.63it/s]\u001b[A\n",
            " 92% 54747/59310 [00:30<00:02, 2074.99it/s]\u001b[A\n",
            " 93% 54955/59310 [00:30<00:02, 2023.12it/s]\u001b[A\n",
            " 93% 55158/59310 [00:30<00:02, 2004.14it/s]\u001b[A\n",
            " 93% 55359/59310 [00:30<00:02, 1952.36it/s]\u001b[A\n",
            " 94% 55558/59310 [00:30<00:01, 1963.05it/s]\u001b[A\n",
            " 94% 55768/59310 [00:30<00:01, 2002.29it/s]\u001b[A\n",
            " 94% 55969/59310 [00:30<00:01, 1967.35it/s]\u001b[A\n",
            " 95% 56172/59310 [00:30<00:01, 1984.74it/s]\u001b[A\n",
            " 95% 56390/59310 [00:30<00:01, 2039.47it/s]\u001b[A\n",
            " 95% 56605/59310 [00:30<00:01, 2069.66it/s]\u001b[A\n",
            " 96% 56813/59310 [00:31<00:01, 2006.17it/s]\u001b[A\n",
            " 96% 57021/59310 [00:31<00:01, 2026.07it/s]\u001b[A\n",
            " 96% 57225/59310 [00:31<00:01, 2018.55it/s]\u001b[A\n",
            " 97% 57438/59310 [00:31<00:00, 2050.67it/s]\u001b[A\n",
            " 97% 57647/59310 [00:31<00:00, 2043.72it/s]\u001b[A\n",
            " 98% 57852/59310 [00:31<00:00, 2005.96it/s]\u001b[A\n",
            " 98% 58061/59310 [00:31<00:00, 2028.13it/s]\u001b[A\n",
            " 98% 58265/59310 [00:31<00:00, 2008.77it/s]\u001b[A\n",
            " 99% 58474/59310 [00:31<00:00, 2029.32it/s]\u001b[A\n",
            " 99% 58683/59310 [00:31<00:00, 2047.04it/s]\u001b[A\n",
            " 99% 58898/59310 [00:32<00:00, 2075.99it/s]\u001b[A\n",
            "100% 59310/59310 [00:32<00:00, 1836.38it/s]\n",
            "1it [00:32, 32.36s/it]\n",
            "No errors! Data is correctly formated!\n",
            "Stats for /content/data/train_instruct.jsonl \n",
            " -------------------- \n",
            " {\n",
            "    \"expected\": {\n",
            "        \"eta\": \"00:08:34\",\n",
            "        \"data_tokens\": 10062027,\n",
            "        \"train_tokens\": 9820800,\n",
            "        \"epochs\": \"0.98\",\n",
            "        \"max_steps\": 300,\n",
            "        \"data_tokens_per_dataset\": {\n",
            "            \"/content/data/train_instruct.jsonl\": \"10062027.0\"\n",
            "        },\n",
            "        \"train_tokens_per_dataset\": {\n",
            "            \"/content/data/train_instruct.jsonl\": \"9820800.0\"\n",
            "        },\n",
            "        \"epochs_per_dataset\": {\n",
            "            \"/content/data/train_instruct.jsonl\": \"1.0\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "0it [00:00, ?it/s]Validating /content/data/test_instruct.jsonl ...\n",
            "\n",
            "  0% 0/5129 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 155/5129 [00:00<00:03, 1536.64it/s]\u001b[A\n",
            "  7% 340/5129 [00:00<00:02, 1717.86it/s]\u001b[A\n",
            " 11% 543/5129 [00:00<00:02, 1855.32it/s]\u001b[A\n",
            " 15% 750/5129 [00:00<00:02, 1937.80it/s]\u001b[A\n",
            " 19% 950/5129 [00:00<00:02, 1958.08it/s]\u001b[A\n",
            " 23% 1156/5129 [00:00<00:01, 1991.88it/s]\u001b[A\n",
            " 27% 1368/5129 [00:00<00:01, 2032.27it/s]\u001b[A\n",
            " 31% 1572/5129 [00:00<00:01, 2025.77it/s]\u001b[A\n",
            " 35% 1786/5129 [00:00<00:01, 2060.16it/s]\u001b[A\n",
            " 39% 1993/5129 [00:01<00:01, 2024.84it/s]\u001b[A\n",
            " 43% 2196/5129 [00:01<00:01, 2013.25it/s]\u001b[A\n",
            " 47% 2398/5129 [00:01<00:01, 1956.48it/s]\u001b[A\n",
            " 51% 2597/5129 [00:01<00:01, 1965.52it/s]\u001b[A\n",
            " 54% 2795/5129 [00:01<00:01, 1967.96it/s]\u001b[A\n",
            " 58% 2999/5129 [00:01<00:01, 1988.02it/s]\u001b[A\n",
            " 63% 3207/5129 [00:01<00:00, 2014.59it/s]\u001b[A\n",
            " 67% 3411/5129 [00:01<00:00, 2019.03it/s]\u001b[A\n",
            " 71% 3619/5129 [00:01<00:00, 2035.93it/s]\u001b[A\n",
            " 75% 3835/5129 [00:01<00:00, 2072.36it/s]\u001b[A\n",
            " 79% 4044/5129 [00:02<00:00, 2074.63it/s]\u001b[A\n",
            " 83% 4252/5129 [00:02<00:00, 2046.89it/s]\u001b[A\n",
            " 87% 4467/5129 [00:02<00:00, 2076.55it/s]\u001b[A\n",
            " 91% 4679/5129 [00:02<00:00, 2088.78it/s]\u001b[A\n",
            " 96% 4899/5129 [00:02<00:00, 2121.19it/s]\u001b[A\n",
            "100% 5129/5129 [00:02<00:00, 2014.69it/s]\n",
            "1it [00:02,  2.56s/it]\n",
            "No errors! Data is correctly formated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "Now that we have our `.yaml` file - we can go ahead an train our model!\n",
        "\n",
        "We need to do a bit of bookkeeping for the Colab environment before moving on."
      ],
      "metadata": {
        "id": "L5oookT3a2i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "metadata": {
        "id": "s7BZAE6pIGM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also make sure that our `OUTPUT_DIR` does not exist to avoid errors."
      ],
      "metadata": {
        "id": "ki1aquDGbRMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/limit_test"
      ],
      "metadata": {
        "id": "KehSn3T4I1xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now - we can train!\n",
        "\n",
        "We'll use `torchrun` to run our `train` script leveraging the created `.yaml` file - and away we go!"
      ],
      "metadata": {
        "id": "5RJuFfyIbXWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!torchrun --nproc-per-node 1 -m train /content/instruct_tune_mistral_7B.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqvbl9ucIMQy",
        "outputId": "0bd509b3-9986-4fe1-af17-2b344dcea51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-05 17:19:19.422143: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-05 17:19:19.476085: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-05 17:19:19.476136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-05 17:19:19.478064: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-05 17:19:19.486942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-05 17:19:20.572072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "args: TrainArgs(data=DataArgs(data='', shuffle=False, instruct_data='/content/data/train_instruct.jsonl', eval_instruct_data='/content/data/test_instruct.jsonl', instruct=InstructArgs(shuffle=True, dynamic_chunk_fn_call=True)), model_id_or_path='/content/mistral_models', run_dir='content/limit_test', optim=OptimArgs(lr=0.0001, weight_decay=0.1, pct_start=0.05), seed=0, num_microbatches=8, seq_len=4092, batch_size=1, max_norm=1.0, max_steps=300, log_freq=1, ckpt_freq=100, save_adapters=True, no_ckpt=False, num_ckpt_keep=3, eval_freq=100, no_eval=False, checkpoint=True, world_size=1, wandb=WandbArgs(project='MistralFinetune', offline=False, key='d86367a6473fa2306be18748d5b31938aec38ce6', run_name='DollyInstruct'), mlflow=MLFlowArgs(tracking_uri=None, experiment_name=None), lora=LoraArgs(enable=True, rank=16, dropout=0.0, scaling=2.0))\n",
            "2024-06-05 17:19:22 (UTC) - 0:00:06 - distributed - INFO - torch.cuda.device_count: 1\n",
            "2024-06-05 17:19:22 (UTC) - 0:00:06 - distributed - INFO - CUDA_VISIBLE_DEVICES: 0\n",
            "2024-06-05 17:19:22 (UTC) - 0:00:06 - distributed - INFO - local rank: 0\n",
            "2024-06-05 17:19:22 (UTC) - 0:00:06 - train - INFO - Going to init comms...\n",
            "2024-06-05 17:19:22 (UTC) - 0:00:06 - train - INFO - Run dir: content/limit_test\n",
            "2024-06-05 17:19:22 (UTC) - 0:00:06 - train - INFO - TrainArgs: {'batch_size': 1,\n",
            " 'checkpoint': True,\n",
            " 'ckpt_freq': 100,\n",
            " 'data': {'data': '',\n",
            "          'eval_instruct_data': '/content/data/test_instruct.jsonl',\n",
            "          'instruct': {'dynamic_chunk_fn_call': True, 'shuffle': True},\n",
            "          'instruct_data': '/content/data/train_instruct.jsonl',\n",
            "          'shuffle': False},\n",
            " 'eval_freq': 100,\n",
            " 'log_freq': 1,\n",
            " 'lora': {'dropout': 0.0, 'enable': True, 'rank': 16, 'scaling': 2.0},\n",
            " 'max_norm': 1.0,\n",
            " 'max_steps': 300,\n",
            " 'mlflow': {'experiment_name': None, 'tracking_uri': None},\n",
            " 'model_id_or_path': '/content/mistral_models',\n",
            " 'no_ckpt': False,\n",
            " 'no_eval': False,\n",
            " 'num_ckpt_keep': 3,\n",
            " 'num_microbatches': 8,\n",
            " 'optim': {'lr': 0.0001, 'pct_start': 0.05, 'weight_decay': 0.1},\n",
            " 'run_dir': 'content/limit_test',\n",
            " 'save_adapters': True,\n",
            " 'seed': 0,\n",
            " 'seq_len': 4092,\n",
            " 'wandb': {'key': 'd86367a6473fa2306be18748d5b31938aec38ce6',\n",
            "           'offline': False,\n",
            "           'project': 'MistralFinetune',\n",
            "           'run_name': 'DollyInstruct'},\n",
            " 'world_size': 1}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisalexiuk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "2024-06-05 17:19:23 (UTC) - 0:00:07 - metrics_logger - INFO - initializing wandb\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mcontent/limit_test/wandb/run-20240605_171923-n7ctsv3t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDollyInstruct\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrisalexiuk/MistralFinetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrisalexiuk/MistralFinetune/runs/n7ctsv3t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "2024-06-05 17:19:27 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Reloading model from /content/mistral_models/consolidated.safetensors ...\n",
            "2024-06-05 17:19:27 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Converting model to dtype torch.bfloat16 ...\n",
            "2024-06-05 17:19:27 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Loaded model on cpu!\n",
            "2024-06-05 17:19:27 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Initializing lora layers ...\n",
            "2024-06-05 17:19:27 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Finished initialization!\n",
            "2024-06-05 17:19:27 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Sharding model over 1 GPUs ...\n",
            "2024-06-05 17:19:32 (UTC) - 0:00:16 - finetune.wrapped_model - INFO - Model sharded!\n",
            "2024-06-05 17:19:32 (UTC) - 0:00:16 - finetune.wrapped_model - INFO - 41,943,040 out of 7,289,966,592 parameter are finetuned (0.58%).\n",
            "2024-06-05 17:19:32 (UTC) - 0:00:16 - dataset - INFO - Loading /content/data/train_instruct.jsonl ...\n",
            "2024-06-05 17:20:09 (UTC) - 0:00:53 - dataset - INFO - /content/data/train_instruct.jsonl loaded and tokenized.\n",
            "2024-06-05 17:20:09 (UTC) - 0:00:53 - dataset - INFO - Shuffling /content/data/train_instruct.jsonl ...\n",
            "2024-06-05 17:20:20 (UTC) - 0:01:04 - train - INFO - step: 000001 - done (%): 0.3 - loss: 1.742 - lr: 4.0e-06 - peak_alloc_mem (GB): 17.0 - alloc_mem (GB): 14.7 - words_per_second: 680.3 - avg_words_per_second: 680.3 - ETA: >2024-06-05 21:20:08\n",
            "2024-06-05 17:20:30 (UTC) - 0:01:14 - train - INFO - step: 000002 - done (%): 0.7 - loss: 1.748 - lr: 5.2e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3323.6 - avg_words_per_second: 1129.4 - ETA: >2024-06-05 19:44:28\n",
            "2024-06-05 17:20:39 (UTC) - 0:01:23 - train - INFO - step: 000003 - done (%): 1.0 - loss: 1.721 - lr: 8.8e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3565.2 - avg_words_per_second: 1462.5 - ETA: >2024-06-05 19:11:27\n",
            "2024-06-05 17:20:49 (UTC) - 0:01:33 - train - INFO - step: 000004 - done (%): 1.3 - loss: 1.735 - lr: 1.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3502.4 - avg_words_per_second: 1711.7 - ETA: >2024-06-05 18:55:10\n",
            "2024-06-05 17:20:58 (UTC) - 0:01:42 - train - INFO - step: 000005 - done (%): 1.7 - loss: 1.710 - lr: 2.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3364.3 - avg_words_per_second: 1898.2 - ETA: >2024-06-05 18:45:46\n",
            "2024-06-05 17:21:08 (UTC) - 0:01:52 - train - INFO - step: 000006 - done (%): 2.0 - loss: 1.681 - lr: 3.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3324.1 - avg_words_per_second: 2044.3 - ETA: >2024-06-05 18:39:36\n",
            "2024-06-05 17:21:17 (UTC) - 0:02:02 - train - INFO - step: 000007 - done (%): 2.3 - loss: 1.731 - lr: 4.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3553.4 - avg_words_per_second: 2176.4 - ETA: >2024-06-05 18:34:45\n",
            "2024-06-05 17:21:27 (UTC) - 0:02:11 - train - INFO - step: 000008 - done (%): 2.7 - loss: 1.674 - lr: 5.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3308.6 - avg_words_per_second: 2273.6 - ETA: >2024-06-05 18:31:32\n",
            "2024-06-05 17:21:37 (UTC) - 0:02:21 - train - INFO - step: 000009 - done (%): 3.0 - loss: 1.671 - lr: 6.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3539.5 - avg_words_per_second: 2367.7 - ETA: >2024-06-05 18:28:40\n",
            "2024-06-05 17:21:46 (UTC) - 0:02:31 - train - INFO - step: 000010 - done (%): 3.3 - loss: 1.598 - lr: 7.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3322.4 - avg_words_per_second: 2437.8 - ETA: >2024-06-05 18:26:41\n",
            "2024-06-05 17:21:56 (UTC) - 0:02:40 - train - INFO - step: 000011 - done (%): 3.7 - loss: 1.549 - lr: 8.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3578.6 - avg_words_per_second: 2510.5 - ETA: >2024-06-05 18:24:44\n",
            "2024-06-05 17:22:05 (UTC) - 0:02:50 - train - INFO - step: 000012 - done (%): 4.0 - loss: 1.544 - lr: 9.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3318.6 - avg_words_per_second: 2562.5 - ETA: >2024-06-05 18:23:25\n",
            "2024-06-05 17:22:15 (UTC) - 0:02:59 - train - INFO - step: 000013 - done (%): 4.3 - loss: 1.511 - lr: 9.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3559.6 - avg_words_per_second: 2619.0 - ETA: >2024-06-05 18:22:02\n",
            "2024-06-05 17:22:25 (UTC) - 0:03:09 - train - INFO - step: 000014 - done (%): 4.7 - loss: 1.595 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3267.6 - avg_words_per_second: 2656.6 - ETA: >2024-06-05 18:21:09\n",
            "2024-06-05 17:22:34 (UTC) - 0:03:18 - train - INFO - step: 000015 - done (%): 5.0 - loss: 1.564 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3534.1 - avg_words_per_second: 2701.3 - ETA: >2024-06-05 18:20:08\n",
            "2024-06-05 17:22:44 (UTC) - 0:03:28 - train - INFO - step: 000016 - done (%): 5.3 - loss: 1.463 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3272.0 - avg_words_per_second: 2731.1 - ETA: >2024-06-05 18:19:28\n",
            "2024-06-05 17:22:53 (UTC) - 0:03:37 - train - INFO - step: 000017 - done (%): 5.7 - loss: 1.413 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3521.6 - avg_words_per_second: 2767.7 - ETA: >2024-06-05 18:18:41\n",
            "2024-06-05 17:23:03 (UTC) - 0:03:47 - train - INFO - step: 000018 - done (%): 6.0 - loss: 1.538 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3245.3 - avg_words_per_second: 2790.5 - ETA: >2024-06-05 18:18:12\n",
            "2024-06-05 17:23:13 (UTC) - 0:03:57 - train - INFO - step: 000019 - done (%): 6.3 - loss: 1.538 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3521.2 - avg_words_per_second: 2821.3 - ETA: >2024-06-05 18:17:33\n",
            "2024-06-05 17:23:23 (UTC) - 0:04:07 - train - INFO - step: 000020 - done (%): 6.7 - loss: 1.486 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3259.3 - avg_words_per_second: 2840.4 - ETA: >2024-06-05 18:17:10\n",
            "2024-06-05 17:23:32 (UTC) - 0:04:16 - train - INFO - step: 000021 - done (%): 7.0 - loss: 1.527 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3466.1 - avg_words_per_second: 2865.0 - ETA: >2024-06-05 18:16:40\n",
            "2024-06-05 17:23:42 (UTC) - 0:04:26 - train - INFO - step: 000022 - done (%): 7.3 - loss: 1.539 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3255.7 - avg_words_per_second: 2880.7 - ETA: >2024-06-05 18:16:21\n",
            "2024-06-05 17:23:52 (UTC) - 0:04:36 - train - INFO - step: 000023 - done (%): 7.7 - loss: 1.575 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3515.7 - avg_words_per_second: 2903.5 - ETA: >2024-06-05 18:15:55\n",
            "2024-06-05 17:24:02 (UTC) - 0:04:46 - train - INFO - step: 000024 - done (%): 8.0 - loss: 1.524 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3262.2 - avg_words_per_second: 2916.9 - ETA: >2024-06-05 18:15:39\n",
            "2024-06-05 17:24:11 (UTC) - 0:04:55 - train - INFO - step: 000025 - done (%): 8.3 - loss: 1.562 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3508.1 - avg_words_per_second: 2936.7 - ETA: >2024-06-05 18:15:16\n",
            "2024-06-05 17:24:21 (UTC) - 0:05:05 - train - INFO - step: 000026 - done (%): 8.7 - loss: 1.485 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3317.7 - avg_words_per_second: 2949.7 - ETA: >2024-06-05 18:15:02\n",
            "2024-06-05 17:24:30 (UTC) - 0:05:14 - train - INFO - step: 000027 - done (%): 9.0 - loss: 1.560 - lr: 1.0e-04 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3522.3 - avg_words_per_second: 2967.6 - ETA: >2024-06-05 18:14:42\n",
            "2024-06-05 17:24:40 (UTC) - 0:05:24 - train - INFO - step: 000028 - done (%): 9.3 - loss: 1.523 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3274.3 - avg_words_per_second: 2977.5 - ETA: >2024-06-05 18:14:31\n",
            "2024-06-05 17:24:50 (UTC) - 0:05:34 - train - INFO - step: 000029 - done (%): 9.7 - loss: 1.409 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3466.0 - avg_words_per_second: 2992.1 - ETA: >2024-06-05 18:14:14\n",
            "2024-06-05 17:25:00 (UTC) - 0:05:44 - train - INFO - step: 000030 - done (%): 10.0 - loss: 1.430 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3250.0 - avg_words_per_second: 3000.0 - ETA: >2024-06-05 18:14:06\n",
            "2024-06-05 17:25:09 (UTC) - 0:05:53 - train - INFO - step: 000031 - done (%): 10.3 - loss: 1.501 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3492.9 - avg_words_per_second: 3013.7 - ETA: >2024-06-05 18:13:51\n",
            "2024-06-05 17:25:19 (UTC) - 0:06:03 - train - INFO - step: 000032 - done (%): 10.7 - loss: 1.471 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3254.8 - avg_words_per_second: 3020.7 - ETA: >2024-06-05 18:13:43\n",
            "2024-06-05 17:25:28 (UTC) - 0:06:12 - train - INFO - step: 000033 - done (%): 11.0 - loss: 1.484 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3499.3 - avg_words_per_second: 3033.3 - ETA: >2024-06-05 18:13:30\n",
            "2024-06-05 17:25:38 (UTC) - 0:06:22 - train - INFO - step: 000034 - done (%): 11.3 - loss: 1.446 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3287.0 - avg_words_per_second: 3040.2 - ETA: >2024-06-05 18:13:23\n",
            "2024-06-05 17:25:48 (UTC) - 0:06:32 - train - INFO - step: 000035 - done (%): 11.7 - loss: 1.541 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3490.3 - avg_words_per_second: 3051.4 - ETA: >2024-06-05 18:13:11\n",
            "2024-06-05 17:25:58 (UTC) - 0:06:42 - train - INFO - step: 000036 - done (%): 12.0 - loss: 1.441 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3254.8 - avg_words_per_second: 3056.7 - ETA: >2024-06-05 18:13:05\n",
            "2024-06-05 17:26:07 (UTC) - 0:06:51 - train - INFO - step: 000037 - done (%): 12.3 - loss: 1.482 - lr: 9.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3507.9 - avg_words_per_second: 3067.4 - ETA: >2024-06-05 18:12:54\n",
            "2024-06-05 17:26:17 (UTC) - 0:07:01 - train - INFO - step: 000038 - done (%): 12.7 - loss: 1.503 - lr: 9.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3271.2 - avg_words_per_second: 3072.4 - ETA: >2024-06-05 18:12:49\n",
            "2024-06-05 17:26:27 (UTC) - 0:07:11 - train - INFO - step: 000039 - done (%): 13.0 - loss: 1.506 - lr: 9.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3482.8 - avg_words_per_second: 3081.7 - ETA: >2024-06-05 18:12:39\n",
            "2024-06-05 17:26:37 (UTC) - 0:07:21 - train - INFO - step: 000040 - done (%): 13.3 - loss: 1.399 - lr: 9.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3236.4 - avg_words_per_second: 3085.4 - ETA: >2024-06-05 18:12:35\n",
            "2024-06-05 17:26:46 (UTC) - 0:07:30 - train - INFO - step: 000041 - done (%): 13.7 - loss: 1.517 - lr: 9.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3533.3 - avg_words_per_second: 3095.0 - ETA: >2024-06-05 18:12:25\n",
            "2024-06-05 17:26:56 (UTC) - 0:07:40 - train - INFO - step: 000042 - done (%): 14.0 - loss: 1.504 - lr: 9.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3294.8 - avg_words_per_second: 3099.5 - ETA: >2024-06-05 18:12:21\n",
            "2024-06-05 17:27:05 (UTC) - 0:07:49 - train - INFO - step: 000043 - done (%): 14.3 - loss: 1.464 - lr: 9.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3536.2 - avg_words_per_second: 3108.4 - ETA: >2024-06-05 18:12:12\n",
            "2024-06-05 17:27:15 (UTC) - 0:07:59 - train - INFO - step: 000044 - done (%): 14.7 - loss: 1.465 - lr: 9.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3313.3 - avg_words_per_second: 3112.8 - ETA: >2024-06-05 18:12:07\n",
            "2024-06-05 17:27:24 (UTC) - 0:08:08 - train - INFO - step: 000045 - done (%): 15.0 - loss: 1.617 - lr: 9.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3572.0 - avg_words_per_second: 3121.7 - ETA: >2024-06-05 18:11:58\n",
            "2024-06-05 17:27:34 (UTC) - 0:08:18 - train - INFO - step: 000046 - done (%): 15.3 - loss: 1.506 - lr: 9.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3338.1 - avg_words_per_second: 3126.1 - ETA: >2024-06-05 18:11:54\n",
            "2024-06-05 17:27:43 (UTC) - 0:08:27 - train - INFO - step: 000047 - done (%): 15.7 - loss: 1.452 - lr: 9.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3561.8 - avg_words_per_second: 3134.3 - ETA: >2024-06-05 18:11:46\n",
            "2024-06-05 17:27:53 (UTC) - 0:08:37 - train - INFO - step: 000048 - done (%): 16.0 - loss: 1.473 - lr: 9.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3254.3 - avg_words_per_second: 3136.7 - ETA: >2024-06-05 18:11:43\n",
            "2024-06-05 17:28:03 (UTC) - 0:08:47 - train - INFO - step: 000049 - done (%): 16.3 - loss: 1.499 - lr: 9.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3508.6 - avg_words_per_second: 3143.5 - ETA: >2024-06-05 18:11:36\n",
            "2024-06-05 17:28:13 (UTC) - 0:08:57 - train - INFO - step: 000050 - done (%): 16.7 - loss: 1.470 - lr: 9.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3258.5 - avg_words_per_second: 3145.7 - ETA: >2024-06-05 18:11:34\n",
            "2024-06-05 17:28:22 (UTC) - 0:09:06 - train - INFO - step: 000051 - done (%): 17.0 - loss: 1.519 - lr: 9.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3499.8 - avg_words_per_second: 3151.9 - ETA: >2024-06-05 18:11:28\n",
            "2024-06-05 17:28:32 (UTC) - 0:09:16 - train - INFO - step: 000052 - done (%): 17.3 - loss: 1.485 - lr: 9.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3259.6 - avg_words_per_second: 3153.9 - ETA: >2024-06-05 18:11:26\n",
            "2024-06-05 17:28:41 (UTC) - 0:09:25 - train - INFO - step: 000053 - done (%): 17.7 - loss: 1.558 - lr: 9.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3506.9 - avg_words_per_second: 3159.9 - ETA: >2024-06-05 18:11:20\n",
            "2024-06-05 17:28:51 (UTC) - 0:09:35 - train - INFO - step: 000054 - done (%): 18.0 - loss: 1.537 - lr: 9.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3338.4 - avg_words_per_second: 3163.1 - ETA: >2024-06-05 18:11:17\n",
            "2024-06-05 17:29:00 (UTC) - 0:09:44 - train - INFO - step: 000055 - done (%): 18.3 - loss: 1.504 - lr: 9.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3556.9 - avg_words_per_second: 3169.5 - ETA: >2024-06-05 18:11:11\n",
            "2024-06-05 17:29:10 (UTC) - 0:09:54 - train - INFO - step: 000056 - done (%): 18.7 - loss: 1.483 - lr: 9.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3333.5 - avg_words_per_second: 3172.2 - ETA: >2024-06-05 18:11:08\n",
            "2024-06-05 17:29:19 (UTC) - 0:10:03 - train - INFO - step: 000057 - done (%): 19.0 - loss: 1.514 - lr: 9.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3566.5 - avg_words_per_second: 3178.4 - ETA: >2024-06-05 18:11:02\n",
            "2024-06-05 17:29:29 (UTC) - 0:10:13 - train - INFO - step: 000058 - done (%): 19.3 - loss: 1.463 - lr: 9.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3355.4 - avg_words_per_second: 3181.3 - ETA: >2024-06-05 18:10:59\n",
            "2024-06-05 17:29:38 (UTC) - 0:10:22 - train - INFO - step: 000059 - done (%): 19.7 - loss: 1.559 - lr: 9.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3581.1 - avg_words_per_second: 3187.3 - ETA: >2024-06-05 18:10:53\n",
            "2024-06-05 17:29:48 (UTC) - 0:10:32 - train - INFO - step: 000060 - done (%): 20.0 - loss: 1.498 - lr: 9.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3286.2 - avg_words_per_second: 3188.9 - ETA: >2024-06-05 18:10:52\n",
            "2024-06-05 17:29:58 (UTC) - 0:10:42 - train - INFO - step: 000061 - done (%): 20.3 - loss: 1.496 - lr: 9.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3475.9 - avg_words_per_second: 3193.3 - ETA: >2024-06-05 18:10:48\n",
            "2024-06-05 17:30:08 (UTC) - 0:10:52 - train - INFO - step: 000062 - done (%): 20.7 - loss: 1.451 - lr: 9.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3265.9 - avg_words_per_second: 3194.4 - ETA: >2024-06-05 18:10:47\n",
            "2024-06-05 17:30:17 (UTC) - 0:11:01 - train - INFO - step: 000063 - done (%): 21.0 - loss: 1.429 - lr: 9.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3501.1 - avg_words_per_second: 3198.9 - ETA: >2024-06-05 18:10:42\n",
            "2024-06-05 17:30:27 (UTC) - 0:11:11 - train - INFO - step: 000064 - done (%): 21.3 - loss: 1.539 - lr: 9.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3277.1 - avg_words_per_second: 3200.0 - ETA: >2024-06-05 18:10:41\n",
            "2024-06-05 17:30:36 (UTC) - 0:11:20 - train - INFO - step: 000065 - done (%): 21.7 - loss: 1.532 - lr: 9.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3491.9 - avg_words_per_second: 3204.2 - ETA: >2024-06-05 18:10:37\n",
            "2024-06-05 17:30:46 (UTC) - 0:11:30 - train - INFO - step: 000066 - done (%): 22.0 - loss: 1.482 - lr: 9.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3296.5 - avg_words_per_second: 3205.5 - ETA: >2024-06-05 18:10:36\n",
            "2024-06-05 17:30:56 (UTC) - 0:11:40 - train - INFO - step: 000067 - done (%): 22.3 - loss: 1.543 - lr: 9.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3543.6 - avg_words_per_second: 3210.1 - ETA: >2024-06-05 18:10:32\n",
            "2024-06-05 17:31:05 (UTC) - 0:11:50 - train - INFO - step: 000068 - done (%): 22.7 - loss: 1.475 - lr: 9.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3306.7 - avg_words_per_second: 3211.5 - ETA: >2024-06-05 18:10:30\n",
            "2024-06-05 17:31:15 (UTC) - 0:11:59 - train - INFO - step: 000069 - done (%): 23.0 - loss: 1.473 - lr: 9.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3539.4 - avg_words_per_second: 3215.8 - ETA: >2024-06-05 18:10:26\n",
            "2024-06-05 17:31:25 (UTC) - 0:12:09 - train - INFO - step: 000070 - done (%): 23.3 - loss: 1.470 - lr: 9.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3331.4 - avg_words_per_second: 3217.4 - ETA: >2024-06-05 18:10:25\n",
            "2024-06-05 17:31:34 (UTC) - 0:12:18 - train - INFO - step: 000071 - done (%): 23.7 - loss: 1.545 - lr: 9.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3552.0 - avg_words_per_second: 3221.7 - ETA: >2024-06-05 18:10:21\n",
            "2024-06-05 17:31:44 (UTC) - 0:12:28 - train - INFO - step: 000072 - done (%): 24.0 - loss: 1.492 - lr: 9.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3338.3 - avg_words_per_second: 3223.2 - ETA: >2024-06-05 18:10:19\n",
            "2024-06-05 17:31:53 (UTC) - 0:12:37 - train - INFO - step: 000073 - done (%): 24.3 - loss: 1.502 - lr: 9.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3520.9 - avg_words_per_second: 3227.0 - ETA: >2024-06-05 18:10:16\n",
            "2024-06-05 17:32:03 (UTC) - 0:12:47 - train - INFO - step: 000074 - done (%): 24.7 - loss: 1.507 - lr: 9.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3310.5 - avg_words_per_second: 3228.1 - ETA: >2024-06-05 18:10:15\n",
            "2024-06-05 17:32:12 (UTC) - 0:12:56 - train - INFO - step: 000075 - done (%): 25.0 - loss: 1.495 - lr: 8.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3547.0 - avg_words_per_second: 3231.9 - ETA: >2024-06-05 18:10:11\n",
            "2024-06-05 17:32:22 (UTC) - 0:13:06 - train - INFO - step: 000076 - done (%): 25.3 - loss: 1.492 - lr: 8.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3308.9 - avg_words_per_second: 3232.9 - ETA: >2024-06-05 18:10:10\n",
            "2024-06-05 17:32:31 (UTC) - 0:13:15 - train - INFO - step: 000077 - done (%): 25.7 - loss: 1.415 - lr: 8.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3542.2 - avg_words_per_second: 3236.6 - ETA: >2024-06-05 18:10:07\n",
            "2024-06-05 17:32:41 (UTC) - 0:13:25 - train - INFO - step: 000078 - done (%): 26.0 - loss: 1.485 - lr: 8.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3361.6 - avg_words_per_second: 3238.1 - ETA: >2024-06-05 18:10:05\n",
            "2024-06-05 17:32:50 (UTC) - 0:13:34 - train - INFO - step: 000079 - done (%): 26.3 - loss: 1.578 - lr: 8.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3560.4 - avg_words_per_second: 3241.9 - ETA: >2024-06-05 18:10:02\n",
            "2024-06-05 17:33:00 (UTC) - 0:13:44 - train - INFO - step: 000080 - done (%): 26.7 - loss: 1.507 - lr: 8.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3335.3 - avg_words_per_second: 3243.0 - ETA: >2024-06-05 18:10:01\n",
            "2024-06-05 17:33:09 (UTC) - 0:13:53 - train - INFO - step: 000081 - done (%): 27.0 - loss: 1.494 - lr: 8.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3523.5 - avg_words_per_second: 3246.2 - ETA: >2024-06-05 18:09:58\n",
            "2024-06-05 17:33:19 (UTC) - 0:14:03 - train - INFO - step: 000082 - done (%): 27.3 - loss: 1.484 - lr: 8.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3336.8 - avg_words_per_second: 3247.3 - ETA: >2024-06-05 18:09:57\n",
            "2024-06-05 17:33:28 (UTC) - 0:14:12 - train - INFO - step: 000083 - done (%): 27.7 - loss: 1.477 - lr: 8.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3535.9 - avg_words_per_second: 3250.5 - ETA: >2024-06-05 18:09:54\n",
            "2024-06-05 17:33:38 (UTC) - 0:14:22 - train - INFO - step: 000084 - done (%): 28.0 - loss: 1.412 - lr: 8.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3315.2 - avg_words_per_second: 3251.2 - ETA: >2024-06-05 18:09:53\n",
            "2024-06-05 17:33:47 (UTC) - 0:14:31 - train - INFO - step: 000085 - done (%): 28.3 - loss: 1.474 - lr: 8.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3546.5 - avg_words_per_second: 3254.4 - ETA: >2024-06-05 18:09:50\n",
            "2024-06-05 17:33:57 (UTC) - 0:14:41 - train - INFO - step: 000086 - done (%): 28.7 - loss: 1.460 - lr: 8.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.5 - avg_words_per_second: 3255.2 - ETA: >2024-06-05 18:09:49\n",
            "2024-06-05 17:34:06 (UTC) - 0:14:51 - train - INFO - step: 000087 - done (%): 29.0 - loss: 1.497 - lr: 8.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3517.8 - avg_words_per_second: 3258.0 - ETA: >2024-06-05 18:09:47\n",
            "2024-06-05 17:34:16 (UTC) - 0:15:00 - train - INFO - step: 000088 - done (%): 29.3 - loss: 1.459 - lr: 8.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3339.3 - avg_words_per_second: 3258.9 - ETA: >2024-06-05 18:09:46\n",
            "2024-06-05 17:34:26 (UTC) - 0:15:10 - train - INFO - step: 000089 - done (%): 29.7 - loss: 1.407 - lr: 8.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3547.1 - avg_words_per_second: 3261.9 - ETA: >2024-06-05 18:09:43\n",
            "2024-06-05 17:34:35 (UTC) - 0:15:19 - train - INFO - step: 000090 - done (%): 30.0 - loss: 1.453 - lr: 8.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.0 - avg_words_per_second: 3262.6 - ETA: >2024-06-05 18:09:42\n",
            "2024-06-05 17:34:45 (UTC) - 0:15:29 - train - INFO - step: 000091 - done (%): 30.3 - loss: 1.552 - lr: 8.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3521.4 - avg_words_per_second: 3265.3 - ETA: >2024-06-05 18:09:40\n",
            "2024-06-05 17:34:54 (UTC) - 0:15:38 - train - INFO - step: 000092 - done (%): 30.7 - loss: 1.487 - lr: 8.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3363.9 - avg_words_per_second: 3266.3 - ETA: >2024-06-05 18:09:39\n",
            "2024-06-05 17:35:04 (UTC) - 0:15:48 - train - INFO - step: 000093 - done (%): 31.0 - loss: 1.446 - lr: 8.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3515.2 - avg_words_per_second: 3268.8 - ETA: >2024-06-05 18:09:37\n",
            "2024-06-05 17:35:14 (UTC) - 0:15:58 - train - INFO - step: 000094 - done (%): 31.3 - loss: 1.419 - lr: 8.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3334.2 - avg_words_per_second: 3269.5 - ETA: >2024-06-05 18:09:36\n",
            "2024-06-05 17:35:23 (UTC) - 0:16:07 - train - INFO - step: 000095 - done (%): 31.7 - loss: 1.550 - lr: 8.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3519.6 - avg_words_per_second: 3271.9 - ETA: >2024-06-05 18:09:34\n",
            "2024-06-05 17:35:33 (UTC) - 0:16:17 - train - INFO - step: 000096 - done (%): 32.0 - loss: 1.466 - lr: 8.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3326.1 - avg_words_per_second: 3272.5 - ETA: >2024-06-05 18:09:33\n",
            "2024-06-05 17:35:42 (UTC) - 0:16:26 - train - INFO - step: 000097 - done (%): 32.3 - loss: 1.564 - lr: 8.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3512.3 - avg_words_per_second: 3274.8 - ETA: >2024-06-05 18:09:31\n",
            "2024-06-05 17:35:52 (UTC) - 0:16:36 - train - INFO - step: 000098 - done (%): 32.7 - loss: 1.380 - lr: 8.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3312.6 - avg_words_per_second: 3275.2 - ETA: >2024-06-05 18:09:31\n",
            "2024-06-05 17:36:01 (UTC) - 0:16:45 - train - INFO - step: 000099 - done (%): 33.0 - loss: 1.460 - lr: 8.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3497.4 - avg_words_per_second: 3277.3 - ETA: >2024-06-05 18:09:29\n",
            "2024-06-05 17:36:11 (UTC) - 0:16:55 - eval - INFO - Start eval...\n",
            "2024-06-05 17:37:19 (UTC) - 0:18:03 - eval - INFO - Eval finished!\n",
            "2024-06-05 17:37:19 (UTC) - 0:18:03 - train - INFO - step: 000100 - eval_perplexity: 2.805 - eval_loss: 1.488 - train_loss: 1.471\n",
            "2024-06-05 17:37:19 (UTC) - 0:18:03 - train - INFO - step: 000100 - done (%): 33.3 - loss: 1.471 - lr: 8.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 420.1 - avg_words_per_second: 3068.5 - ETA: >2024-06-05 18:12:53\n",
            "2024-06-05 17:37:19 (UTC) - 0:18:03 - checkpointing - INFO - Dumping checkpoint in content/limit_test/checkpoints/checkpoint_000100/consolidated using tmp name: tmp.consolidated\n",
            "2024-06-05 17:37:20 (UTC) - 0:18:04 - checkpointing - INFO - Done dumping checkpoint in content/limit_test/checkpoints/checkpoint_000100/consolidated for step: 100\n",
            "2024-06-05 17:37:20 (UTC) - 0:18:04 - checkpointing - INFO - Done deleting checkpoints \n",
            "2024-06-05 17:37:20 (UTC) - 0:18:04 - checkpointing - INFO - Done!\n",
            "2024-06-05 17:37:29 (UTC) - 0:18:13 - train - INFO - step: 000101 - done (%): 33.7 - loss: 1.472 - lr: 7.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3483.5 - avg_words_per_second: 3072.2 - ETA: >2024-06-05 18:12:50\n",
            "2024-06-05 17:37:39 (UTC) - 0:18:23 - train - INFO - step: 000102 - done (%): 34.0 - loss: 1.500 - lr: 7.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3352.1 - avg_words_per_second: 3074.7 - ETA: >2024-06-05 18:12:47\n",
            "2024-06-05 17:37:48 (UTC) - 0:18:32 - train - INFO - step: 000103 - done (%): 34.3 - loss: 1.457 - lr: 7.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3505.1 - avg_words_per_second: 3078.4 - ETA: >2024-06-05 18:12:43\n",
            "2024-06-05 17:37:58 (UTC) - 0:18:42 - train - INFO - step: 000104 - done (%): 34.7 - loss: 1.534 - lr: 7.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3336.8 - avg_words_per_second: 3080.7 - ETA: >2024-06-05 18:12:41\n",
            "2024-06-05 17:38:07 (UTC) - 0:18:51 - train - INFO - step: 000105 - done (%): 35.0 - loss: 1.531 - lr: 7.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3519.7 - avg_words_per_second: 3084.3 - ETA: >2024-06-05 18:12:37\n",
            "2024-06-05 17:38:17 (UTC) - 0:19:01 - train - INFO - step: 000106 - done (%): 35.3 - loss: 1.453 - lr: 7.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3335.7 - avg_words_per_second: 3086.5 - ETA: >2024-06-05 18:12:35\n",
            "2024-06-05 17:38:26 (UTC) - 0:19:10 - train - INFO - step: 000107 - done (%): 35.7 - loss: 1.439 - lr: 7.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3519.7 - avg_words_per_second: 3090.1 - ETA: >2024-06-05 18:12:31\n",
            "2024-06-05 17:38:36 (UTC) - 0:19:20 - train - INFO - step: 000108 - done (%): 36.0 - loss: 1.381 - lr: 7.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.3 - avg_words_per_second: 3092.1 - ETA: >2024-06-05 18:12:29\n",
            "2024-06-05 17:38:46 (UTC) - 0:19:30 - train - INFO - step: 000109 - done (%): 36.3 - loss: 1.503 - lr: 7.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3520.3 - avg_words_per_second: 3095.6 - ETA: >2024-06-05 18:12:25\n",
            "2024-06-05 17:38:55 (UTC) - 0:19:39 - train - INFO - step: 000110 - done (%): 36.7 - loss: 1.492 - lr: 7.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3344.7 - avg_words_per_second: 3097.7 - ETA: >2024-06-05 18:12:23\n",
            "2024-06-05 17:39:05 (UTC) - 0:19:49 - train - INFO - step: 000111 - done (%): 37.0 - loss: 1.435 - lr: 7.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3546.8 - avg_words_per_second: 3101.2 - ETA: >2024-06-05 18:12:20\n",
            "2024-06-05 17:39:14 (UTC) - 0:19:58 - train - INFO - step: 000112 - done (%): 37.3 - loss: 1.512 - lr: 7.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3354.4 - avg_words_per_second: 3103.3 - ETA: >2024-06-05 18:12:18\n",
            "2024-06-05 17:39:24 (UTC) - 0:20:08 - train - INFO - step: 000113 - done (%): 37.7 - loss: 1.429 - lr: 7.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3532.8 - avg_words_per_second: 3106.6 - ETA: >2024-06-05 18:12:14\n",
            "2024-06-05 17:39:33 (UTC) - 0:20:17 - train - INFO - step: 000114 - done (%): 38.0 - loss: 1.464 - lr: 7.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3354.9 - avg_words_per_second: 3108.6 - ETA: >2024-06-05 18:12:12\n",
            "2024-06-05 17:39:43 (UTC) - 0:20:27 - train - INFO - step: 000115 - done (%): 38.3 - loss: 1.451 - lr: 7.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3533.7 - avg_words_per_second: 3111.9 - ETA: >2024-06-05 18:12:09\n",
            "2024-06-05 17:39:52 (UTC) - 0:20:36 - train - INFO - step: 000116 - done (%): 38.7 - loss: 1.525 - lr: 7.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3341.1 - avg_words_per_second: 3113.7 - ETA: >2024-06-05 18:12:07\n",
            "2024-06-05 17:40:02 (UTC) - 0:20:46 - train - INFO - step: 000117 - done (%): 39.0 - loss: 1.461 - lr: 7.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3512.4 - avg_words_per_second: 3116.8 - ETA: >2024-06-05 18:12:04\n",
            "2024-06-05 17:40:12 (UTC) - 0:20:56 - train - INFO - step: 000118 - done (%): 39.3 - loss: 1.465 - lr: 7.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3331.6 - avg_words_per_second: 3118.5 - ETA: >2024-06-05 18:12:02\n",
            "2024-06-05 17:40:21 (UTC) - 0:21:05 - train - INFO - step: 000119 - done (%): 39.7 - loss: 1.465 - lr: 7.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3520.8 - avg_words_per_second: 3121.5 - ETA: >2024-06-05 18:11:59\n",
            "2024-06-05 17:40:31 (UTC) - 0:21:15 - train - INFO - step: 000120 - done (%): 40.0 - loss: 1.511 - lr: 7.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3321.3 - avg_words_per_second: 3123.0 - ETA: >2024-06-05 18:11:58\n",
            "2024-06-05 17:40:40 (UTC) - 0:21:24 - train - INFO - step: 000121 - done (%): 40.3 - loss: 1.406 - lr: 7.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3507.6 - avg_words_per_second: 3125.9 - ETA: >2024-06-05 18:11:55\n",
            "2024-06-05 17:40:50 (UTC) - 0:21:34 - train - INFO - step: 000122 - done (%): 40.7 - loss: 1.481 - lr: 6.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3326.1 - avg_words_per_second: 3127.4 - ETA: >2024-06-05 18:11:53\n",
            "2024-06-05 17:40:59 (UTC) - 0:21:43 - train - INFO - step: 000123 - done (%): 41.0 - loss: 1.589 - lr: 6.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3504.0 - avg_words_per_second: 3130.1 - ETA: >2024-06-05 18:11:50\n",
            "2024-06-05 17:41:09 (UTC) - 0:21:53 - train - INFO - step: 000124 - done (%): 41.3 - loss: 1.366 - lr: 6.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3347.9 - avg_words_per_second: 3131.8 - ETA: >2024-06-05 18:11:49\n",
            "2024-06-05 17:41:18 (UTC) - 0:22:02 - train - INFO - step: 000125 - done (%): 41.7 - loss: 1.464 - lr: 6.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3534.9 - avg_words_per_second: 3134.6 - ETA: >2024-06-05 18:11:46\n",
            "2024-06-05 17:41:28 (UTC) - 0:22:12 - train - INFO - step: 000126 - done (%): 42.0 - loss: 1.443 - lr: 6.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3362.3 - avg_words_per_second: 3136.3 - ETA: >2024-06-05 18:11:44\n",
            "2024-06-05 17:41:37 (UTC) - 0:22:21 - train - INFO - step: 000127 - done (%): 42.3 - loss: 1.505 - lr: 6.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3513.1 - avg_words_per_second: 3139.0 - ETA: >2024-06-05 18:11:42\n",
            "2024-06-05 17:41:47 (UTC) - 0:22:31 - train - INFO - step: 000128 - done (%): 42.7 - loss: 1.520 - lr: 6.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3366.4 - avg_words_per_second: 3140.6 - ETA: >2024-06-05 18:11:40\n",
            "2024-06-05 17:41:56 (UTC) - 0:22:40 - train - INFO - step: 000129 - done (%): 43.0 - loss: 1.504 - lr: 6.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3519.6 - avg_words_per_second: 3143.3 - ETA: >2024-06-05 18:11:37\n",
            "2024-06-05 17:42:06 (UTC) - 0:22:50 - train - INFO - step: 000130 - done (%): 43.3 - loss: 1.466 - lr: 6.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3375.2 - avg_words_per_second: 3144.9 - ETA: >2024-06-05 18:11:36\n",
            "2024-06-05 17:42:16 (UTC) - 0:23:00 - train - INFO - step: 000131 - done (%): 43.7 - loss: 1.486 - lr: 6.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3328.9 - avg_words_per_second: 3146.3 - ETA: >2024-06-05 18:11:34\n",
            "2024-06-05 17:42:25 (UTC) - 0:23:09 - train - INFO - step: 000132 - done (%): 44.0 - loss: 1.533 - lr: 6.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3547.6 - avg_words_per_second: 3149.0 - ETA: >2024-06-05 18:11:32\n",
            "2024-06-05 17:42:35 (UTC) - 0:23:19 - train - INFO - step: 000133 - done (%): 44.3 - loss: 1.426 - lr: 6.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3299.9 - avg_words_per_second: 3150.0 - ETA: >2024-06-05 18:11:31\n",
            "2024-06-05 17:42:44 (UTC) - 0:23:28 - train - INFO - step: 000134 - done (%): 44.7 - loss: 1.452 - lr: 6.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3564.1 - avg_words_per_second: 3152.8 - ETA: >2024-06-05 18:11:28\n",
            "2024-06-05 17:42:54 (UTC) - 0:23:38 - train - INFO - step: 000135 - done (%): 45.0 - loss: 1.440 - lr: 6.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3496.8 - avg_words_per_second: 3155.1 - ETA: >2024-06-05 18:11:26\n",
            "2024-06-05 17:43:03 (UTC) - 0:23:47 - train - INFO - step: 000136 - done (%): 45.3 - loss: 1.452 - lr: 6.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3362.6 - avg_words_per_second: 3156.5 - ETA: >2024-06-05 18:11:24\n",
            "2024-06-05 17:43:13 (UTC) - 0:23:57 - train - INFO - step: 000137 - done (%): 45.7 - loss: 1.540 - lr: 6.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3329.6 - avg_words_per_second: 3157.7 - ETA: >2024-06-05 18:11:23\n",
            "2024-06-05 17:43:22 (UTC) - 0:24:07 - train - INFO - step: 000138 - done (%): 46.0 - loss: 1.492 - lr: 6.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3537.5 - avg_words_per_second: 3160.2 - ETA: >2024-06-05 18:11:21\n",
            "2024-06-05 17:43:32 (UTC) - 0:24:16 - train - INFO - step: 000139 - done (%): 46.3 - loss: 1.461 - lr: 6.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3307.1 - avg_words_per_second: 3161.2 - ETA: >2024-06-05 18:11:20\n",
            "2024-06-05 17:43:42 (UTC) - 0:24:26 - train - INFO - step: 000140 - done (%): 46.7 - loss: 1.427 - lr: 6.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3557.5 - avg_words_per_second: 3163.7 - ETA: >2024-06-05 18:11:17\n",
            "2024-06-05 17:43:51 (UTC) - 0:24:35 - train - INFO - step: 000141 - done (%): 47.0 - loss: 1.575 - lr: 5.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3321.1 - avg_words_per_second: 3164.8 - ETA: >2024-06-05 18:11:16\n",
            "2024-06-05 17:44:01 (UTC) - 0:24:45 - train - INFO - step: 000142 - done (%): 47.3 - loss: 1.400 - lr: 5.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3556.6 - avg_words_per_second: 3167.2 - ETA: >2024-06-05 18:11:14\n",
            "2024-06-05 17:44:10 (UTC) - 0:24:55 - train - INFO - step: 000143 - done (%): 47.7 - loss: 1.477 - lr: 5.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3316.1 - avg_words_per_second: 3168.2 - ETA: >2024-06-05 18:11:13\n",
            "2024-06-05 17:44:20 (UTC) - 0:25:04 - train - INFO - step: 000144 - done (%): 48.0 - loss: 1.360 - lr: 5.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3558.5 - avg_words_per_second: 3170.6 - ETA: >2024-06-05 18:11:10\n",
            "2024-06-05 17:44:30 (UTC) - 0:25:14 - train - INFO - step: 000145 - done (%): 48.3 - loss: 1.561 - lr: 5.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3322.0 - avg_words_per_second: 3171.6 - ETA: >2024-06-05 18:11:09\n",
            "2024-06-05 17:44:39 (UTC) - 0:25:23 - train - INFO - step: 000146 - done (%): 48.7 - loss: 1.408 - lr: 5.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3566.6 - avg_words_per_second: 3174.0 - ETA: >2024-06-05 18:11:07\n",
            "2024-06-05 17:44:49 (UTC) - 0:25:33 - train - INFO - step: 000147 - done (%): 49.0 - loss: 1.467 - lr: 5.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3311.4 - avg_words_per_second: 3174.9 - ETA: >2024-06-05 18:11:06\n",
            "2024-06-05 17:44:58 (UTC) - 0:25:42 - train - INFO - step: 000148 - done (%): 49.3 - loss: 1.463 - lr: 5.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3544.3 - avg_words_per_second: 3177.2 - ETA: >2024-06-05 18:11:04\n",
            "2024-06-05 17:45:08 (UTC) - 0:25:52 - train - INFO - step: 000149 - done (%): 49.7 - loss: 1.428 - lr: 5.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3335.1 - avg_words_per_second: 3178.2 - ETA: >2024-06-05 18:11:03\n",
            "2024-06-05 17:45:17 (UTC) - 0:26:01 - train - INFO - step: 000150 - done (%): 50.0 - loss: 1.421 - lr: 5.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3557.4 - avg_words_per_second: 3180.4 - ETA: >2024-06-05 18:11:01\n",
            "2024-06-05 17:45:27 (UTC) - 0:26:11 - train - INFO - step: 000151 - done (%): 50.3 - loss: 1.496 - lr: 5.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3323.0 - avg_words_per_second: 3181.3 - ETA: >2024-06-05 18:11:00\n",
            "2024-06-05 17:45:36 (UTC) - 0:26:20 - train - INFO - step: 000152 - done (%): 50.7 - loss: 1.471 - lr: 5.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3546.6 - avg_words_per_second: 3183.5 - ETA: >2024-06-05 18:10:58\n",
            "2024-06-05 17:45:46 (UTC) - 0:26:30 - train - INFO - step: 000153 - done (%): 51.0 - loss: 1.390 - lr: 5.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3301.4 - avg_words_per_second: 3184.2 - ETA: >2024-06-05 18:10:57\n",
            "2024-06-05 17:45:55 (UTC) - 0:26:39 - train - INFO - step: 000154 - done (%): 51.3 - loss: 1.481 - lr: 5.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3558.3 - avg_words_per_second: 3186.4 - ETA: >2024-06-05 18:10:55\n",
            "2024-06-05 17:46:05 (UTC) - 0:26:49 - train - INFO - step: 000155 - done (%): 51.7 - loss: 1.423 - lr: 5.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3294.5 - avg_words_per_second: 3187.1 - ETA: >2024-06-05 18:10:54\n",
            "2024-06-05 17:46:14 (UTC) - 0:26:58 - train - INFO - step: 000156 - done (%): 52.0 - loss: 1.399 - lr: 5.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3554.1 - avg_words_per_second: 3189.2 - ETA: >2024-06-05 18:10:52\n",
            "2024-06-05 17:46:24 (UTC) - 0:27:08 - train - INFO - step: 000157 - done (%): 52.3 - loss: 1.524 - lr: 5.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3309.4 - avg_words_per_second: 3189.9 - ETA: >2024-06-05 18:10:52\n",
            "2024-06-05 17:46:33 (UTC) - 0:27:17 - train - INFO - step: 000158 - done (%): 52.7 - loss: 1.475 - lr: 5.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3555.2 - avg_words_per_second: 3192.0 - ETA: >2024-06-05 18:10:50\n",
            "2024-06-05 17:46:43 (UTC) - 0:27:27 - train - INFO - step: 000159 - done (%): 53.0 - loss: 1.507 - lr: 4.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3333.5 - avg_words_per_second: 3192.9 - ETA: >2024-06-05 18:10:49\n",
            "2024-06-05 17:46:52 (UTC) - 0:27:36 - train - INFO - step: 000160 - done (%): 53.3 - loss: 1.482 - lr: 4.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3547.7 - avg_words_per_second: 3194.9 - ETA: >2024-06-05 18:10:47\n",
            "2024-06-05 17:47:02 (UTC) - 0:27:46 - train - INFO - step: 000161 - done (%): 53.7 - loss: 1.393 - lr: 4.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3313.0 - avg_words_per_second: 3195.6 - ETA: >2024-06-05 18:10:46\n",
            "2024-06-05 17:47:12 (UTC) - 0:27:56 - train - INFO - step: 000162 - done (%): 54.0 - loss: 1.461 - lr: 4.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3545.9 - avg_words_per_second: 3197.5 - ETA: >2024-06-05 18:10:44\n",
            "2024-06-05 17:47:21 (UTC) - 0:28:05 - train - INFO - step: 000163 - done (%): 54.3 - loss: 1.477 - lr: 4.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3298.4 - avg_words_per_second: 3198.1 - ETA: >2024-06-05 18:10:44\n",
            "2024-06-05 17:47:31 (UTC) - 0:28:15 - train - INFO - step: 000164 - done (%): 54.7 - loss: 1.495 - lr: 4.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3554.7 - avg_words_per_second: 3200.1 - ETA: >2024-06-05 18:10:42\n",
            "2024-06-05 17:47:41 (UTC) - 0:28:25 - train - INFO - step: 000165 - done (%): 55.0 - loss: 1.419 - lr: 4.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3316.0 - avg_words_per_second: 3200.7 - ETA: >2024-06-05 18:10:41\n",
            "2024-06-05 17:47:50 (UTC) - 0:28:34 - train - INFO - step: 000166 - done (%): 55.3 - loss: 1.447 - lr: 4.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3572.5 - avg_words_per_second: 3202.8 - ETA: >2024-06-05 18:10:39\n",
            "2024-06-05 17:48:00 (UTC) - 0:28:44 - train - INFO - step: 000167 - done (%): 55.7 - loss: 1.430 - lr: 4.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3333.8 - avg_words_per_second: 3203.5 - ETA: >2024-06-05 18:10:39\n",
            "2024-06-05 17:48:09 (UTC) - 0:28:53 - train - INFO - step: 000168 - done (%): 56.0 - loss: 1.441 - lr: 4.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3543.9 - avg_words_per_second: 3205.3 - ETA: >2024-06-05 18:10:37\n",
            "2024-06-05 17:48:19 (UTC) - 0:29:03 - train - INFO - step: 000169 - done (%): 56.3 - loss: 1.382 - lr: 4.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3300.9 - avg_words_per_second: 3205.9 - ETA: >2024-06-05 18:10:36\n",
            "2024-06-05 17:48:28 (UTC) - 0:29:12 - train - INFO - step: 000170 - done (%): 56.7 - loss: 1.492 - lr: 4.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3543.7 - avg_words_per_second: 3207.7 - ETA: >2024-06-05 18:10:35\n",
            "2024-06-05 17:48:38 (UTC) - 0:29:22 - train - INFO - step: 000171 - done (%): 57.0 - loss: 1.439 - lr: 4.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3312.7 - avg_words_per_second: 3208.3 - ETA: >2024-06-05 18:10:34\n",
            "2024-06-05 17:48:47 (UTC) - 0:29:31 - train - INFO - step: 000172 - done (%): 57.3 - loss: 1.450 - lr: 4.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3536.9 - avg_words_per_second: 3210.0 - ETA: >2024-06-05 18:10:32\n",
            "2024-06-05 17:48:57 (UTC) - 0:29:41 - train - INFO - step: 000173 - done (%): 57.7 - loss: 1.491 - lr: 4.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3309.4 - avg_words_per_second: 3210.6 - ETA: >2024-06-05 18:10:32\n",
            "2024-06-05 17:49:06 (UTC) - 0:29:50 - train - INFO - step: 000174 - done (%): 58.0 - loss: 1.440 - lr: 4.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3541.8 - avg_words_per_second: 3212.3 - ETA: >2024-06-05 18:10:30\n",
            "2024-06-05 17:49:16 (UTC) - 0:30:00 - train - INFO - step: 000175 - done (%): 58.3 - loss: 1.443 - lr: 4.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3292.2 - avg_words_per_second: 3212.7 - ETA: >2024-06-05 18:10:30\n",
            "2024-06-05 17:49:25 (UTC) - 0:30:09 - train - INFO - step: 000176 - done (%): 58.7 - loss: 1.487 - lr: 4.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3557.2 - avg_words_per_second: 3214.5 - ETA: >2024-06-05 18:10:28\n",
            "2024-06-05 17:49:35 (UTC) - 0:30:19 - train - INFO - step: 000177 - done (%): 59.0 - loss: 1.440 - lr: 3.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3300.4 - avg_words_per_second: 3215.0 - ETA: >2024-06-05 18:10:28\n",
            "2024-06-05 17:49:44 (UTC) - 0:30:29 - train - INFO - step: 000178 - done (%): 59.3 - loss: 1.481 - lr: 3.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3558.9 - avg_words_per_second: 3216.7 - ETA: >2024-06-05 18:10:26\n",
            "2024-06-05 17:49:54 (UTC) - 0:30:38 - train - INFO - step: 000179 - done (%): 59.7 - loss: 1.526 - lr: 3.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3318.7 - avg_words_per_second: 3217.3 - ETA: >2024-06-05 18:10:26\n",
            "2024-06-05 17:50:03 (UTC) - 0:30:48 - train - INFO - step: 000180 - done (%): 60.0 - loss: 1.477 - lr: 3.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3586.9 - avg_words_per_second: 3219.1 - ETA: >2024-06-05 18:10:24\n",
            "2024-06-05 17:50:13 (UTC) - 0:30:57 - train - INFO - step: 000181 - done (%): 60.3 - loss: 1.542 - lr: 3.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3307.9 - avg_words_per_second: 3219.6 - ETA: >2024-06-05 18:10:23\n",
            "2024-06-05 17:50:23 (UTC) - 0:31:07 - train - INFO - step: 000182 - done (%): 60.7 - loss: 1.439 - lr: 3.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3558.3 - avg_words_per_second: 3221.3 - ETA: >2024-06-05 18:10:22\n",
            "2024-06-05 17:50:32 (UTC) - 0:31:16 - train - INFO - step: 000183 - done (%): 61.0 - loss: 1.554 - lr: 3.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3318.3 - avg_words_per_second: 3221.8 - ETA: >2024-06-05 18:10:21\n",
            "2024-06-05 17:50:42 (UTC) - 0:31:26 - train - INFO - step: 000184 - done (%): 61.3 - loss: 1.389 - lr: 3.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3572.2 - avg_words_per_second: 3223.5 - ETA: >2024-06-05 18:10:20\n",
            "2024-06-05 17:50:51 (UTC) - 0:31:36 - train - INFO - step: 000185 - done (%): 61.7 - loss: 1.510 - lr: 3.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3318.0 - avg_words_per_second: 3224.0 - ETA: >2024-06-05 18:10:19\n",
            "2024-06-05 17:51:01 (UTC) - 0:31:45 - train - INFO - step: 000186 - done (%): 62.0 - loss: 1.403 - lr: 3.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3586.2 - avg_words_per_second: 3225.8 - ETA: >2024-06-05 18:10:17\n",
            "2024-06-05 17:51:10 (UTC) - 0:31:54 - train - INFO - step: 000187 - done (%): 62.3 - loss: 1.330 - lr: 3.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3335.6 - avg_words_per_second: 3226.3 - ETA: >2024-06-05 18:10:17\n",
            "2024-06-05 17:51:20 (UTC) - 0:32:04 - train - INFO - step: 000188 - done (%): 62.7 - loss: 1.495 - lr: 3.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3571.8 - avg_words_per_second: 3228.0 - ETA: >2024-06-05 18:10:15\n",
            "2024-06-05 17:51:29 (UTC) - 0:32:13 - train - INFO - step: 000189 - done (%): 63.0 - loss: 1.464 - lr: 3.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3334.2 - avg_words_per_second: 3228.5 - ETA: >2024-06-05 18:10:15\n",
            "2024-06-05 17:51:39 (UTC) - 0:32:23 - train - INFO - step: 000190 - done (%): 63.3 - loss: 1.487 - lr: 3.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3550.7 - avg_words_per_second: 3230.1 - ETA: >2024-06-05 18:10:13\n",
            "2024-06-05 17:51:49 (UTC) - 0:32:33 - train - INFO - step: 000191 - done (%): 63.7 - loss: 1.430 - lr: 3.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3290.3 - avg_words_per_second: 3230.4 - ETA: >2024-06-05 18:10:13\n",
            "2024-06-05 17:51:58 (UTC) - 0:32:42 - train - INFO - step: 000192 - done (%): 64.0 - loss: 1.449 - lr: 3.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3509.9 - avg_words_per_second: 3231.7 - ETA: >2024-06-05 18:10:12\n",
            "2024-06-05 17:52:08 (UTC) - 0:32:52 - train - INFO - step: 000193 - done (%): 64.3 - loss: 1.463 - lr: 3.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3319.6 - avg_words_per_second: 3232.2 - ETA: >2024-06-05 18:10:11\n",
            "2024-06-05 17:52:17 (UTC) - 0:33:01 - train - INFO - step: 000194 - done (%): 64.7 - loss: 1.472 - lr: 3.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3561.4 - avg_words_per_second: 3233.7 - ETA: >2024-06-05 18:10:10\n",
            "2024-06-05 17:52:27 (UTC) - 0:33:11 - train - INFO - step: 000195 - done (%): 65.0 - loss: 1.431 - lr: 3.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3321.1 - avg_words_per_second: 3234.2 - ETA: >2024-06-05 18:10:10\n",
            "2024-06-05 17:52:36 (UTC) - 0:33:20 - train - INFO - step: 000196 - done (%): 65.3 - loss: 1.485 - lr: 2.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3558.6 - avg_words_per_second: 3235.7 - ETA: >2024-06-05 18:10:08\n",
            "2024-06-05 17:52:46 (UTC) - 0:33:30 - train - INFO - step: 000197 - done (%): 65.7 - loss: 1.359 - lr: 2.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3321.8 - avg_words_per_second: 3236.1 - ETA: >2024-06-05 18:10:08\n",
            "2024-06-05 17:52:55 (UTC) - 0:33:39 - train - INFO - step: 000198 - done (%): 66.0 - loss: 1.531 - lr: 2.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3585.6 - avg_words_per_second: 3237.7 - ETA: >2024-06-05 18:10:06\n",
            "2024-06-05 17:53:05 (UTC) - 0:33:49 - train - INFO - step: 000199 - done (%): 66.3 - loss: 1.438 - lr: 2.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3308.7 - avg_words_per_second: 3238.0 - ETA: >2024-06-05 18:10:06\n",
            "2024-06-05 17:53:14 (UTC) - 0:33:58 - eval - INFO - Start eval...\n",
            "2024-06-05 17:54:22 (UTC) - 0:35:06 - eval - INFO - Eval finished!\n",
            "2024-06-05 17:54:22 (UTC) - 0:35:06 - train - INFO - step: 000200 - eval_perplexity: 2.759 - eval_loss: 1.464 - train_loss: 1.423\n",
            "2024-06-05 17:54:22 (UTC) - 0:35:06 - train - INFO - step: 000200 - done (%): 66.7 - loss: 1.423 - lr: 2.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 423.5 - avg_words_per_second: 3133.9 - ETA: >2024-06-05 18:11:47\n",
            "2024-06-05 17:54:22 (UTC) - 0:35:06 - checkpointing - INFO - Dumping checkpoint in content/limit_test/checkpoints/checkpoint_000200/consolidated using tmp name: tmp.consolidated\n",
            "2024-06-05 17:54:23 (UTC) - 0:35:07 - checkpointing - INFO - Done dumping checkpoint in content/limit_test/checkpoints/checkpoint_000200/consolidated for step: 200\n",
            "2024-06-05 17:54:23 (UTC) - 0:35:07 - checkpointing - INFO - Done deleting checkpoints \n",
            "2024-06-05 17:54:23 (UTC) - 0:35:07 - checkpointing - INFO - Done!\n",
            "2024-06-05 17:54:33 (UTC) - 0:35:17 - train - INFO - step: 000201 - done (%): 67.0 - loss: 1.411 - lr: 2.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3315.0 - avg_words_per_second: 3134.7 - ETA: >2024-06-05 18:11:46\n",
            "2024-06-05 17:54:42 (UTC) - 0:35:26 - train - INFO - step: 000202 - done (%): 67.3 - loss: 1.469 - lr: 2.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3537.5 - avg_words_per_second: 3136.5 - ETA: >2024-06-05 18:11:45\n",
            "2024-06-05 17:54:52 (UTC) - 0:35:36 - train - INFO - step: 000203 - done (%): 67.7 - loss: 1.440 - lr: 2.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3313.9 - avg_words_per_second: 3137.3 - ETA: >2024-06-05 18:11:44\n",
            "2024-06-05 17:55:01 (UTC) - 0:35:45 - train - INFO - step: 000204 - done (%): 68.0 - loss: 1.434 - lr: 2.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3545.9 - avg_words_per_second: 3139.1 - ETA: >2024-06-05 18:11:42\n",
            "2024-06-05 17:55:11 (UTC) - 0:35:55 - train - INFO - step: 000205 - done (%): 68.3 - loss: 1.444 - lr: 2.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3317.0 - avg_words_per_second: 3139.9 - ETA: >2024-06-05 18:11:41\n",
            "2024-06-05 17:55:20 (UTC) - 0:36:04 - train - INFO - step: 000206 - done (%): 68.7 - loss: 1.470 - lr: 2.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3557.3 - avg_words_per_second: 3141.7 - ETA: >2024-06-05 18:11:39\n",
            "2024-06-05 17:55:30 (UTC) - 0:36:14 - train - INFO - step: 000207 - done (%): 69.0 - loss: 1.505 - lr: 2.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.6 - avg_words_per_second: 3142.6 - ETA: >2024-06-05 18:11:39\n",
            "2024-06-05 17:55:39 (UTC) - 0:36:23 - train - INFO - step: 000208 - done (%): 69.3 - loss: 1.418 - lr: 2.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3562.2 - avg_words_per_second: 3144.3 - ETA: >2024-06-05 18:11:37\n",
            "2024-06-05 17:55:49 (UTC) - 0:36:33 - train - INFO - step: 000209 - done (%): 69.7 - loss: 1.533 - lr: 2.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3340.2 - avg_words_per_second: 3145.2 - ETA: >2024-06-05 18:11:36\n",
            "2024-06-05 17:55:58 (UTC) - 0:36:42 - train - INFO - step: 000210 - done (%): 70.0 - loss: 1.449 - lr: 2.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3554.2 - avg_words_per_second: 3147.0 - ETA: >2024-06-05 18:11:34\n",
            "2024-06-05 17:56:08 (UTC) - 0:36:52 - train - INFO - step: 000211 - done (%): 70.3 - loss: 1.457 - lr: 2.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3317.5 - avg_words_per_second: 3147.7 - ETA: >2024-06-05 18:11:33\n",
            "2024-06-05 17:56:17 (UTC) - 0:37:01 - train - INFO - step: 000212 - done (%): 70.7 - loss: 1.398 - lr: 2.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3541.1 - avg_words_per_second: 3149.4 - ETA: >2024-06-05 18:11:32\n",
            "2024-06-05 17:56:27 (UTC) - 0:37:11 - train - INFO - step: 000213 - done (%): 71.0 - loss: 1.408 - lr: 2.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3343.5 - avg_words_per_second: 3150.2 - ETA: >2024-06-05 18:11:31\n",
            "2024-06-05 17:56:36 (UTC) - 0:37:20 - train - INFO - step: 000214 - done (%): 71.3 - loss: 1.424 - lr: 2.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3537.4 - avg_words_per_second: 3151.8 - ETA: >2024-06-05 18:11:29\n",
            "2024-06-05 17:56:46 (UTC) - 0:37:30 - train - INFO - step: 000215 - done (%): 71.7 - loss: 1.449 - lr: 2.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3325.1 - avg_words_per_second: 3152.6 - ETA: >2024-06-05 18:11:29\n",
            "2024-06-05 17:56:55 (UTC) - 0:37:39 - train - INFO - step: 000216 - done (%): 72.0 - loss: 1.500 - lr: 2.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3549.1 - avg_words_per_second: 3154.2 - ETA: >2024-06-05 18:11:27\n",
            "2024-06-05 17:57:05 (UTC) - 0:37:49 - train - INFO - step: 000217 - done (%): 72.3 - loss: 1.405 - lr: 2.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3322.5 - avg_words_per_second: 3155.0 - ETA: >2024-06-05 18:11:26\n",
            "2024-06-05 17:57:14 (UTC) - 0:37:58 - train - INFO - step: 000218 - done (%): 72.7 - loss: 1.479 - lr: 1.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3525.6 - avg_words_per_second: 3156.5 - ETA: >2024-06-05 18:11:25\n",
            "2024-06-05 17:57:24 (UTC) - 0:38:08 - train - INFO - step: 000219 - done (%): 73.0 - loss: 1.473 - lr: 1.9e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3308.5 - avg_words_per_second: 3157.2 - ETA: >2024-06-05 18:11:24\n",
            "2024-06-05 17:57:34 (UTC) - 0:38:18 - train - INFO - step: 000220 - done (%): 73.3 - loss: 1.459 - lr: 1.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3535.0 - avg_words_per_second: 3158.7 - ETA: >2024-06-05 18:11:23\n",
            "2024-06-05 17:57:43 (UTC) - 0:38:27 - train - INFO - step: 000221 - done (%): 73.7 - loss: 1.406 - lr: 1.8e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3344.0 - avg_words_per_second: 3159.5 - ETA: >2024-06-05 18:11:22\n",
            "2024-06-05 17:57:53 (UTC) - 0:38:37 - train - INFO - step: 000222 - done (%): 74.0 - loss: 1.316 - lr: 1.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3525.2 - avg_words_per_second: 3161.0 - ETA: >2024-06-05 18:11:20\n",
            "2024-06-05 17:58:03 (UTC) - 0:38:47 - train - INFO - step: 000223 - done (%): 74.3 - loss: 1.418 - lr: 1.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3310.3 - avg_words_per_second: 3161.6 - ETA: >2024-06-05 18:11:20\n",
            "2024-06-05 17:58:12 (UTC) - 0:38:56 - train - INFO - step: 000224 - done (%): 74.7 - loss: 1.386 - lr: 1.7e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3522.6 - avg_words_per_second: 3163.0 - ETA: >2024-06-05 18:11:18\n",
            "2024-06-05 17:58:22 (UTC) - 0:39:06 - train - INFO - step: 000225 - done (%): 75.0 - loss: 1.438 - lr: 1.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3316.1 - avg_words_per_second: 3163.7 - ETA: >2024-06-05 18:11:18\n",
            "2024-06-05 17:58:31 (UTC) - 0:39:15 - train - INFO - step: 000226 - done (%): 75.3 - loss: 1.515 - lr: 1.6e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3513.6 - avg_words_per_second: 3165.1 - ETA: >2024-06-05 18:11:16\n",
            "2024-06-05 17:58:41 (UTC) - 0:39:25 - train - INFO - step: 000227 - done (%): 75.7 - loss: 1.409 - lr: 1.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3315.2 - avg_words_per_second: 3165.7 - ETA: >2024-06-05 18:11:16\n",
            "2024-06-05 17:58:50 (UTC) - 0:39:34 - train - INFO - step: 000228 - done (%): 76.0 - loss: 1.524 - lr: 1.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3546.7 - avg_words_per_second: 3167.2 - ETA: >2024-06-05 18:11:14\n",
            "2024-06-05 17:59:00 (UTC) - 0:39:44 - train - INFO - step: 000229 - done (%): 76.3 - loss: 1.401 - lr: 1.5e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3337.2 - avg_words_per_second: 3167.9 - ETA: >2024-06-05 18:11:14\n",
            "2024-06-05 17:59:09 (UTC) - 0:39:53 - train - INFO - step: 000230 - done (%): 76.7 - loss: 1.510 - lr: 1.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3555.7 - avg_words_per_second: 3169.4 - ETA: >2024-06-05 18:11:12\n",
            "2024-06-05 17:59:19 (UTC) - 0:40:03 - train - INFO - step: 000231 - done (%): 77.0 - loss: 1.358 - lr: 1.4e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3325.8 - avg_words_per_second: 3170.1 - ETA: >2024-06-05 18:11:12\n",
            "2024-06-05 17:59:28 (UTC) - 0:40:12 - train - INFO - step: 000232 - done (%): 77.3 - loss: 1.468 - lr: 1.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3539.6 - avg_words_per_second: 3171.5 - ETA: >2024-06-05 18:11:10\n",
            "2024-06-05 17:59:38 (UTC) - 0:40:22 - train - INFO - step: 000233 - done (%): 77.7 - loss: 1.453 - lr: 1.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3335.6 - avg_words_per_second: 3172.2 - ETA: >2024-06-05 18:11:09\n",
            "2024-06-05 17:59:47 (UTC) - 0:40:31 - train - INFO - step: 000234 - done (%): 78.0 - loss: 1.452 - lr: 1.3e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3563.5 - avg_words_per_second: 3173.7 - ETA: >2024-06-05 18:11:08\n",
            "2024-06-05 17:59:57 (UTC) - 0:40:41 - train - INFO - step: 000235 - done (%): 78.3 - loss: 1.432 - lr: 1.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3334.3 - avg_words_per_second: 3174.3 - ETA: >2024-06-05 18:11:07\n",
            "2024-06-05 18:00:06 (UTC) - 0:40:50 - train - INFO - step: 000236 - done (%): 78.7 - loss: 1.398 - lr: 1.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3542.1 - avg_words_per_second: 3175.7 - ETA: >2024-06-05 18:11:06\n",
            "2024-06-05 18:00:16 (UTC) - 0:41:00 - train - INFO - step: 000237 - done (%): 79.0 - loss: 1.516 - lr: 1.2e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3335.1 - avg_words_per_second: 3176.3 - ETA: >2024-06-05 18:11:05\n",
            "2024-06-05 18:00:25 (UTC) - 0:41:09 - train - INFO - step: 000238 - done (%): 79.3 - loss: 1.404 - lr: 1.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3561.3 - avg_words_per_second: 3177.8 - ETA: >2024-06-05 18:11:04\n",
            "2024-06-05 18:00:35 (UTC) - 0:41:19 - train - INFO - step: 000239 - done (%): 79.7 - loss: 1.443 - lr: 1.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3350.9 - avg_words_per_second: 3178.5 - ETA: >2024-06-05 18:11:03\n",
            "2024-06-05 18:00:44 (UTC) - 0:41:28 - train - INFO - step: 000240 - done (%): 80.0 - loss: 1.455 - lr: 1.1e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3550.4 - avg_words_per_second: 3179.9 - ETA: >2024-06-05 18:11:02\n",
            "2024-06-05 18:00:54 (UTC) - 0:41:38 - train - INFO - step: 000241 - done (%): 80.3 - loss: 1.434 - lr: 1.0e-05 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3315.6 - avg_words_per_second: 3180.4 - ETA: >2024-06-05 18:11:01\n",
            "2024-06-05 18:01:03 (UTC) - 0:41:47 - train - INFO - step: 000242 - done (%): 80.7 - loss: 1.483 - lr: 9.9e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3548.2 - avg_words_per_second: 3181.8 - ETA: >2024-06-05 18:11:00\n",
            "2024-06-05 18:01:13 (UTC) - 0:41:57 - train - INFO - step: 000243 - done (%): 81.0 - loss: 1.531 - lr: 9.5e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.6 - avg_words_per_second: 3182.3 - ETA: >2024-06-05 18:11:00\n",
            "2024-06-05 18:01:23 (UTC) - 0:42:07 - train - INFO - step: 000244 - done (%): 81.3 - loss: 1.452 - lr: 9.2e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3524.2 - avg_words_per_second: 3183.6 - ETA: >2024-06-05 18:10:58\n",
            "2024-06-05 18:01:32 (UTC) - 0:42:16 - train - INFO - step: 000245 - done (%): 81.7 - loss: 1.403 - lr: 8.9e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3325.9 - avg_words_per_second: 3184.2 - ETA: >2024-06-05 18:10:58\n",
            "2024-06-05 18:01:42 (UTC) - 0:42:26 - train - INFO - step: 000246 - done (%): 82.0 - loss: 1.469 - lr: 8.6e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3547.2 - avg_words_per_second: 3185.5 - ETA: >2024-06-05 18:10:57\n",
            "2024-06-05 18:01:51 (UTC) - 0:42:35 - train - INFO - step: 000247 - done (%): 82.3 - loss: 1.447 - lr: 8.3e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3337.3 - avg_words_per_second: 3186.1 - ETA: >2024-06-05 18:10:56\n",
            "2024-06-05 18:02:01 (UTC) - 0:42:45 - train - INFO - step: 000248 - done (%): 82.7 - loss: 1.448 - lr: 8.0e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3527.8 - avg_words_per_second: 3187.3 - ETA: >2024-06-05 18:10:55\n",
            "2024-06-05 18:02:11 (UTC) - 0:42:55 - train - INFO - step: 000249 - done (%): 83.0 - loss: 1.485 - lr: 7.7e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3310.1 - avg_words_per_second: 3187.8 - ETA: >2024-06-05 18:10:54\n",
            "2024-06-05 18:02:20 (UTC) - 0:43:04 - train - INFO - step: 000250 - done (%): 83.3 - loss: 1.460 - lr: 7.4e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3516.9 - avg_words_per_second: 3189.0 - ETA: >2024-06-05 18:10:53\n",
            "2024-06-05 18:02:30 (UTC) - 0:43:14 - train - INFO - step: 000251 - done (%): 83.7 - loss: 1.469 - lr: 7.1e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3291.1 - avg_words_per_second: 3189.4 - ETA: >2024-06-05 18:10:53\n",
            "2024-06-05 18:02:39 (UTC) - 0:43:23 - train - INFO - step: 000252 - done (%): 84.0 - loss: 1.463 - lr: 6.8e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3532.0 - avg_words_per_second: 3190.6 - ETA: >2024-06-05 18:10:52\n",
            "2024-06-05 18:02:49 (UTC) - 0:43:33 - train - INFO - step: 000253 - done (%): 84.3 - loss: 1.506 - lr: 6.6e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.9 - avg_words_per_second: 3191.1 - ETA: >2024-06-05 18:10:51\n",
            "2024-06-05 18:02:58 (UTC) - 0:43:42 - train - INFO - step: 000254 - done (%): 84.7 - loss: 1.423 - lr: 6.3e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3525.4 - avg_words_per_second: 3192.3 - ETA: >2024-06-05 18:10:50\n",
            "2024-06-05 18:03:08 (UTC) - 0:43:52 - train - INFO - step: 000255 - done (%): 85.0 - loss: 1.363 - lr: 6.0e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3308.8 - avg_words_per_second: 3192.8 - ETA: >2024-06-05 18:10:50\n",
            "2024-06-05 18:03:17 (UTC) - 0:44:02 - train - INFO - step: 000256 - done (%): 85.3 - loss: 1.404 - lr: 5.8e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3527.9 - avg_words_per_second: 3193.9 - ETA: >2024-06-05 18:10:48\n",
            "2024-06-05 18:03:27 (UTC) - 0:44:11 - train - INFO - step: 000257 - done (%): 85.7 - loss: 1.530 - lr: 5.5e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3324.1 - avg_words_per_second: 3194.4 - ETA: >2024-06-05 18:10:48\n",
            "2024-06-05 18:03:37 (UTC) - 0:44:21 - train - INFO - step: 000258 - done (%): 86.0 - loss: 1.391 - lr: 5.3e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3532.5 - avg_words_per_second: 3195.6 - ETA: >2024-06-05 18:10:47\n",
            "2024-06-05 18:03:46 (UTC) - 0:44:30 - train - INFO - step: 000259 - done (%): 86.3 - loss: 1.385 - lr: 5.0e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3314.4 - avg_words_per_second: 3196.1 - ETA: >2024-06-05 18:10:46\n",
            "2024-06-05 18:03:56 (UTC) - 0:44:40 - train - INFO - step: 000260 - done (%): 86.7 - loss: 1.460 - lr: 4.8e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3533.3 - avg_words_per_second: 3197.2 - ETA: >2024-06-05 18:10:45\n",
            "2024-06-05 18:04:06 (UTC) - 0:44:50 - train - INFO - step: 000261 - done (%): 87.0 - loss: 1.341 - lr: 4.6e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3310.0 - avg_words_per_second: 3197.7 - ETA: >2024-06-05 18:10:45\n",
            "2024-06-05 18:04:15 (UTC) - 0:44:59 - train - INFO - step: 000262 - done (%): 87.3 - loss: 1.371 - lr: 4.3e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3525.6 - avg_words_per_second: 3198.8 - ETA: >2024-06-05 18:10:44\n",
            "2024-06-05 18:04:25 (UTC) - 0:45:09 - train - INFO - step: 000263 - done (%): 87.7 - loss: 1.451 - lr: 4.1e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3294.1 - avg_words_per_second: 3199.1 - ETA: >2024-06-05 18:10:43\n",
            "2024-06-05 18:04:34 (UTC) - 0:45:18 - train - INFO - step: 000264 - done (%): 88.0 - loss: 1.402 - lr: 3.9e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3531.4 - avg_words_per_second: 3200.3 - ETA: >2024-06-05 18:10:42\n",
            "2024-06-05 18:04:44 (UTC) - 0:45:28 - train - INFO - step: 000265 - done (%): 88.3 - loss: 1.408 - lr: 3.7e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3313.4 - avg_words_per_second: 3200.7 - ETA: >2024-06-05 18:10:42\n",
            "2024-06-05 18:04:53 (UTC) - 0:45:37 - train - INFO - step: 000266 - done (%): 88.7 - loss: 1.397 - lr: 3.5e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3520.7 - avg_words_per_second: 3201.8 - ETA: >2024-06-05 18:10:41\n",
            "2024-06-05 18:05:03 (UTC) - 0:45:47 - train - INFO - step: 000267 - done (%): 89.0 - loss: 1.558 - lr: 3.3e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3299.0 - avg_words_per_second: 3202.1 - ETA: >2024-06-05 18:10:41\n",
            "2024-06-05 18:05:12 (UTC) - 0:45:57 - train - INFO - step: 000268 - done (%): 89.3 - loss: 1.262 - lr: 3.1e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3534.5 - avg_words_per_second: 3203.3 - ETA: >2024-06-05 18:10:40\n",
            "2024-06-05 18:05:22 (UTC) - 0:46:06 - train - INFO - step: 000269 - done (%): 89.7 - loss: 1.442 - lr: 2.9e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.6 - avg_words_per_second: 3203.7 - ETA: >2024-06-05 18:10:39\n",
            "2024-06-05 18:05:32 (UTC) - 0:46:16 - train - INFO - step: 000270 - done (%): 90.0 - loss: 1.459 - lr: 2.7e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3512.2 - avg_words_per_second: 3204.7 - ETA: >2024-06-05 18:10:38\n",
            "2024-06-05 18:05:42 (UTC) - 0:46:26 - train - INFO - step: 000271 - done (%): 90.3 - loss: 1.435 - lr: 2.5e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3308.0 - avg_words_per_second: 3205.1 - ETA: >2024-06-05 18:10:38\n",
            "2024-06-05 18:05:51 (UTC) - 0:46:35 - train - INFO - step: 000272 - done (%): 90.7 - loss: 1.431 - lr: 2.4e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3528.7 - avg_words_per_second: 3206.2 - ETA: >2024-06-05 18:10:37\n",
            "2024-06-05 18:06:01 (UTC) - 0:46:45 - train - INFO - step: 000273 - done (%): 91.0 - loss: 1.459 - lr: 2.2e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3327.9 - avg_words_per_second: 3206.6 - ETA: >2024-06-05 18:10:36\n",
            "2024-06-05 18:06:10 (UTC) - 0:46:54 - train - INFO - step: 000274 - done (%): 91.3 - loss: 1.451 - lr: 2.0e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3531.4 - avg_words_per_second: 3207.7 - ETA: >2024-06-05 18:10:35\n",
            "2024-06-05 18:06:20 (UTC) - 0:47:04 - train - INFO - step: 000275 - done (%): 91.7 - loss: 1.467 - lr: 1.9e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3311.4 - avg_words_per_second: 3208.1 - ETA: >2024-06-05 18:10:35\n",
            "2024-06-05 18:06:29 (UTC) - 0:47:13 - train - INFO - step: 000276 - done (%): 92.0 - loss: 1.435 - lr: 1.7e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3506.7 - avg_words_per_second: 3209.1 - ETA: >2024-06-05 18:10:34\n",
            "2024-06-05 18:06:39 (UTC) - 0:47:23 - train - INFO - step: 000277 - done (%): 92.3 - loss: 1.464 - lr: 1.6e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3306.4 - avg_words_per_second: 3209.4 - ETA: >2024-06-05 18:10:34\n",
            "2024-06-05 18:06:48 (UTC) - 0:47:32 - train - INFO - step: 000278 - done (%): 92.7 - loss: 1.447 - lr: 1.5e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3553.6 - avg_words_per_second: 3210.5 - ETA: >2024-06-05 18:10:33\n",
            "2024-06-05 18:06:58 (UTC) - 0:47:42 - train - INFO - step: 000279 - done (%): 93.0 - loss: 1.542 - lr: 1.3e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3320.6 - avg_words_per_second: 3210.9 - ETA: >2024-06-05 18:10:32\n",
            "2024-06-05 18:07:07 (UTC) - 0:47:51 - train - INFO - step: 000280 - done (%): 93.3 - loss: 1.459 - lr: 1.2e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3548.6 - avg_words_per_second: 3212.0 - ETA: >2024-06-05 18:10:31\n",
            "2024-06-05 18:07:17 (UTC) - 0:48:01 - train - INFO - step: 000281 - done (%): 93.7 - loss: 1.468 - lr: 1.1e-06 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3311.8 - avg_words_per_second: 3212.3 - ETA: >2024-06-05 18:10:31\n",
            "2024-06-05 18:07:26 (UTC) - 0:48:11 - train - INFO - step: 000282 - done (%): 94.0 - loss: 1.445 - lr: 9.8e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3554.1 - avg_words_per_second: 3213.4 - ETA: >2024-06-05 18:10:30\n",
            "2024-06-05 18:07:36 (UTC) - 0:48:20 - train - INFO - step: 000283 - done (%): 94.3 - loss: 1.401 - lr: 8.8e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3332.8 - avg_words_per_second: 3213.8 - ETA: >2024-06-05 18:10:29\n",
            "2024-06-05 18:07:45 (UTC) - 0:48:30 - train - INFO - step: 000284 - done (%): 94.7 - loss: 1.474 - lr: 7.8e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3556.2 - avg_words_per_second: 3214.9 - ETA: >2024-06-05 18:10:28\n",
            "2024-06-05 18:07:55 (UTC) - 0:48:39 - train - INFO - step: 000285 - done (%): 95.0 - loss: 1.377 - lr: 6.8e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3299.3 - avg_words_per_second: 3215.2 - ETA: >2024-06-05 18:10:28\n",
            "2024-06-05 18:08:05 (UTC) - 0:48:49 - train - INFO - step: 000286 - done (%): 95.3 - loss: 1.385 - lr: 5.9e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3537.1 - avg_words_per_second: 3216.2 - ETA: >2024-06-05 18:10:27\n",
            "2024-06-05 18:08:15 (UTC) - 0:48:59 - train - INFO - step: 000287 - done (%): 95.7 - loss: 1.444 - lr: 5.1e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3310.2 - avg_words_per_second: 3216.6 - ETA: >2024-06-05 18:10:27\n",
            "2024-06-05 18:08:24 (UTC) - 0:49:08 - train - INFO - step: 000288 - done (%): 96.0 - loss: 1.380 - lr: 4.4e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3511.2 - avg_words_per_second: 3217.5 - ETA: >2024-06-05 18:10:26\n",
            "2024-06-05 18:08:34 (UTC) - 0:49:18 - train - INFO - step: 000289 - done (%): 96.3 - loss: 1.490 - lr: 3.7e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3314.7 - avg_words_per_second: 3217.8 - ETA: >2024-06-05 18:10:26\n",
            "2024-06-05 18:08:43 (UTC) - 0:49:27 - train - INFO - step: 000290 - done (%): 96.7 - loss: 1.517 - lr: 3.0e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3537.4 - avg_words_per_second: 3218.8 - ETA: >2024-06-05 18:10:25\n",
            "2024-06-05 18:08:53 (UTC) - 0:49:37 - train - INFO - step: 000291 - done (%): 97.0 - loss: 1.528 - lr: 2.5e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3330.5 - avg_words_per_second: 3219.2 - ETA: >2024-06-05 18:10:24\n",
            "2024-06-05 18:09:02 (UTC) - 0:49:46 - train - INFO - step: 000292 - done (%): 97.3 - loss: 1.491 - lr: 1.9e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3552.4 - avg_words_per_second: 3220.2 - ETA: >2024-06-05 18:10:23\n",
            "2024-06-05 18:09:12 (UTC) - 0:49:56 - train - INFO - step: 000293 - done (%): 97.7 - loss: 1.434 - lr: 1.5e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3345.9 - avg_words_per_second: 3220.6 - ETA: >2024-06-05 18:10:23\n",
            "2024-06-05 18:09:21 (UTC) - 0:50:05 - train - INFO - step: 000294 - done (%): 98.0 - loss: 1.515 - lr: 1.1e-07 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3524.6 - avg_words_per_second: 3221.6 - ETA: >2024-06-05 18:10:22\n",
            "2024-06-05 18:09:31 (UTC) - 0:50:15 - train - INFO - step: 000295 - done (%): 98.3 - loss: 1.324 - lr: 7.6e-08 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3320.1 - avg_words_per_second: 3221.9 - ETA: >2024-06-05 18:10:22\n",
            "2024-06-05 18:09:34 (UTC) - 0:50:19 - dataset - INFO - Shuffling /content/data/train_instruct.jsonl ...\n",
            "2024-06-05 18:09:40 (UTC) - 0:50:24 - train - INFO - step: 000296 - done (%): 98.7 - loss: 1.498 - lr: 4.9e-08 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3519.6 - avg_words_per_second: 3222.8 - ETA: >2024-06-05 18:10:21\n",
            "2024-06-05 18:09:50 (UTC) - 0:50:34 - train - INFO - step: 000297 - done (%): 99.0 - loss: 1.365 - lr: 2.8e-08 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3289.2 - avg_words_per_second: 3223.1 - ETA: >2024-06-05 18:10:21\n",
            "2024-06-05 18:10:00 (UTC) - 0:50:44 - train - INFO - step: 000298 - done (%): 99.3 - loss: 1.445 - lr: 1.3e-08 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3532.9 - avg_words_per_second: 3224.0 - ETA: >2024-06-05 18:10:20\n",
            "2024-06-05 18:10:09 (UTC) - 0:50:53 - train - INFO - step: 000299 - done (%): 99.7 - loss: 1.374 - lr: 3.4e-09 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 3322.1 - avg_words_per_second: 3224.3 - ETA: >2024-06-05 18:10:20\n",
            "2024-06-05 18:10:19 (UTC) - 0:51:03 - eval - INFO - Start eval...\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - eval - INFO - Eval finished!\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - train - INFO - step: 000300 - eval_perplexity: 2.749 - eval_loss: 1.459 - train_loss: 1.417\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - train - INFO - step: 000300 - done (%): 100.0 - loss: 1.417 - lr: 4.0e-10 - peak_alloc_mem (GB): 17.3 - alloc_mem (GB): 14.7 - words_per_second: 423.2 - avg_words_per_second: 3154.7 - ETA: >2024-06-05 18:11:27\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - checkpointing - INFO - Dumping checkpoint in content/limit_test/checkpoints/checkpoint_000300/consolidated using tmp name: tmp.consolidated\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - checkpointing - INFO - Done dumping checkpoint in content/limit_test/checkpoints/checkpoint_000300/consolidated for step: 300\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - checkpointing - INFO - Done deleting checkpoints \n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - checkpointing - INFO - Done!\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - train - INFO - done!\n",
            "2024-06-05 18:11:27 (UTC) - 0:52:11 - utils - INFO - Closing: eval_logger\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/eval_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/perplexity █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/train_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/allocated_mem ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/avg_wps ▁▄▆▆▇▇▇██████▇▇▇▇▇████████▇▇▇██████████▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/eta_in_seconds █▆▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss █▇▄▅▄▃▄▄▅▄▄▃▄▄▃▅▃▅▃▄▄▄▄▄▃▄▃▃▅▃▅▃▄▄▄▁▄▄▄▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/lr ▂▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/peak_allocated_mem ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/percent_done ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/wps █▇▇▇▇▇▇▇▇▇▇▇█▁▇▇██████████▁████████████▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/eval_loss 1.45867\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/perplexity 2.74855\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/train_loss 1.41747\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/allocated_mem 14.70247\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/avg_wps 3154.72285\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/eta_in_seconds 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 1.41747\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/peak_allocated_mem 17.26623\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/percent_done 100.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/wps 423.2183\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDollyInstruct\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/chrisalexiuk/MistralFinetune/runs/n7ctsv3t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/chrisalexiuk/MistralFinetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mcontent/limit_test/wandb/run-20240605_171923-n7ctsv3t/logs\u001b[0m\n",
            "2024-06-05 18:11:32 (UTC) - 0:52:16 - utils - INFO - Closed: eval_logger\n",
            "2024-06-05 18:11:32 (UTC) - 0:52:16 - utils - INFO - Closing: metrics_logger\n",
            "2024-06-05 18:11:32 (UTC) - 0:52:16 - utils - INFO - Closed: metrics_logger\n",
            "2024-06-05 18:11:32 (UTC) - 0:52:16 - train - INFO - Closed everything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with Mistral\n",
        "\n",
        "Now that we have a trained model - let's see how it responds!\n",
        "\n",
        "First up  - let's install the `mistral_inference` library."
      ],
      "metadata": {
        "id": "yYRBlJzcblCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU mistral_inference"
      ],
      "metadata": {
        "id": "putipLEtMeZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the `transformers` library - we have a set of useful imports that, for the most part, just do what they say!"
      ],
      "metadata": {
        "id": "Uf1D3Fp2buAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mistral_inference.model import Transformer\n",
        "from mistral_inference.generate import generate\n",
        "\n",
        "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
        "from mistral_common.protocol.instruct.messages import UserMessage, SystemMessage\n",
        "from mistral_common.protocol.instruct.request import ChatCompletionRequest"
      ],
      "metadata": {
        "id": "VADxwKcGMpLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can load our downloaded model, our downloaded tokenizer, and our fine-tuned adapter!"
      ],
      "metadata": {
        "id": "aL-q69TLb2oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = MistralTokenizer.from_file(\"/content/mistral_models/tokenizer.model.v3\")\n",
        "model = Transformer.from_folder(\"/content/mistral_models\")\n",
        "model.load_lora(\"/content/limit_test/checkpoints/checkpoint_000100/consolidated/lora.safetensors\")"
      ],
      "metadata": {
        "id": "n7UqmPXNMrVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a very familiar format - we can create a request to our model!\n",
        "\n",
        "We'll be sure to use the Instruction template we created before, and give a sample request!"
      ],
      "metadata": {
        "id": "nYMHOGjPcCLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion_request = ChatCompletionRequest(\n",
        "    messages=\n",
        "      [\n",
        "        SystemMessage(content=\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"),\n",
        "        UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")\n",
        "      ]\n",
        ")"
      ],
      "metadata": {
        "id": "zp59Ys2tM0q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll go ahead an tokenize our chat completion!"
      ],
      "metadata": {
        "id": "nlvzyhLEcyq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_chat_completion(completion_request).tokens"
      ],
      "metadata": {
        "id": "h-4jYJUINQg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can generate a response and see how it did!"
      ],
      "metadata": {
        "id": "fRvVWZNZc119"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
        "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])"
      ],
      "metadata": {
        "id": "j_JTPGdsNSMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvX4pPYfNUvC",
        "outputId": "73d8ffd8-5370-4f58-b645-96b5de0e4d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning is a subset of Artificial Intelligence that allows computers to learn from data without being explicitly programmed. Machine Learning algorithms use statistical techniques to give computers the ability to learn without being explicitly programmed. Machine Learning focuses on the development of computer programs that can access data and use it to learn for themselves.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a suitable response! Great job model!"
      ],
      "metadata": {
        "id": "WD9PkrKUc6cX"
      }
    }
  ]
}