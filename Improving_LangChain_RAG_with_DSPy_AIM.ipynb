{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Improving LangChain RAG with DSPy\n",
        "\n",
        "In the following notebook, we'll explore the integration between DSPy and LangChain!\n",
        "\n",
        "Using this integration we can take advantage of the familiarity of LangChain and LCEL, with the addition of the power of DSPy for LLM-interaction optimization."
      ],
      "metadata": {
        "id": "jBIf7DT_o-dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API Keys and Dependencies\n",
        "\n",
        "We'll provide our OpenAI API key, and install all the required libraries for this example!"
      ],
      "metadata": {
        "id": "5jxJ2KjHpbAS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZjr-UC2L_rT",
        "outputId": "268c9833-138d-4fe3-e85b-1c8aef452abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key:Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll want LangChain, PyDantic, and DSPy first and foremost.\n",
        "\n",
        "> NOTE: As of the time of recording (07/24/2023) `dspy_ai==2.1.4` is required to ensure the notebook runs."
      ],
      "metadata": {
        "id": "ow8oiONJpkEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain==0.2.7 pydantic==2.8.2 dspy_ai==2.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyDNExe-NImV",
        "outputId": "f4a5f2d8-05f2-4b68-80dd-58e723de3723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we'll install our LangChain community packages."
      ],
      "metadata": {
        "id": "DJVl36KDppAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_openai langchain_community langchain_core langchain_qdrant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR5lzpbVbfLy",
        "outputId": "e88cb3fe-3207-44a3-8b64-b337022bf012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/46.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.2 which is incompatible.\n",
            "dspy-ai 2.1.4 requires openai~=0.28.1, but you have openai 1.37.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigtable 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also install our engines for the above community packages."
      ],
      "metadata": {
        "id": "d3SbzFqXpsG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU qdrant-client pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtzIvERTblfp",
        "outputId": "171bfe71-e54f-480f-873a-b77eb55fb54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RAG with LCEL\n",
        "\n",
        "To begin, things will look very similar to traditional LCEL RAG with LangChain!\n",
        "\n",
        "Let's start by grabbing our document that we'll be focusing on for this session!"
      ],
      "metadata": {
        "id": "RkPeaAo1pvK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "document_loader = PyMuPDFLoader(\"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\")\n",
        "documents = document_loader.load()"
      ],
      "metadata": {
        "id": "iC_vb5-FNDhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we'll chunk our document into bitesized pieces of context."
      ],
      "metadata": {
        "id": "EzzG-CUAp5vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "split_documents = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "XFfHBJxuYvoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we'll embed our chunked documents into a vectorstore - for this example we'll be using QDrant, but you could substitute your favourite vector database, vector store, or retriever here."
      ],
      "metadata": {
        "id": "evnFIracqAa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    split_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca\",\n",
        ")"
      ],
      "metadata": {
        "id": "RrdFgtYjQC3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll finally conform our vectorstore to a retriever."
      ],
      "metadata": {
        "id": "dYJv5Fw2qmVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "rFfG1HfmQgXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll set a cache since we'll be making a lot of LLM calls throughout the notebook today.\n",
        "\n"
      ],
      "metadata": {
        "id": "-2CHCexOqwb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_llm_cache\n",
        "from langchain_community.cache import SQLiteCache\n",
        "\n",
        "set_llm_cache(SQLiteCache(database_path=\"cache.db\"))"
      ],
      "metadata": {
        "id": "O8jK3JLLRN8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll set-up a helper function for our retriever to work in the expected fashion for our LCEL chain below."
      ],
      "metadata": {
        "id": "pS74kwgMq9oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(inputs):\n",
        "  return [doc.page_content for doc in retriever.invoke(inputs[\"question\"])]"
      ],
      "metadata": {
        "id": "M6QePIMdRSTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be using the new `gpt-4o-mini` as our base LLM today - check out more details about this new, inexpensive model, [here](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)!"
      ],
      "metadata": {
        "id": "QA-9n3rhrHFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "Hpsy_6_6VGqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll set our initial prompt - which will be optimized by DSPy - and initialize our LCEL chain.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9g-Uhhi9rT2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Given {context}, answer the question `{question}` as a tweet. Your response should only contain the tweet.\"\n",
        ")\n",
        "\n",
        "naive_rag_chain = (\n",
        "    RunnablePassthrough.assign(context=retrieve) | prompt | llm | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "KLtMoIv6Rpnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DSPy Integration\n",
        "\n",
        "So far in the notebook, we've been relying on LangChain - but it's finally time to integrate DSPy!\n",
        "\n",
        "We're going to rely on two key integrations:\n",
        "\n",
        "- [`LangChainPredict`](https://github.com/stanfordnlp/dspy/blob/af5617aec7b298f8688e68d6087804e702e61ba0/dspy/predict/langchain.py#L34) - The `LangChainPredict` class bridges LangChain's language models with DSPy's prediction framework. It manages prompt generation, model execution, and result handling, while also offering features for state management and input/output structure determination.\n",
        "- [`LangChainModule`](https://github.com/stanfordnlp/dspy/blob/af5617aec7b298f8688e68d6087804e702e61ba0/dspy/predict/langchain.py#L139) - The `LangChainModule` class wraps a LangChain Expression Language (LCEL) chain into a DSPy module. It extracts `LangChainPredict` instances from the LCEL graph, handles the chain's execution, and formats the output to be compatible with DSPy's prediction framework.\n",
        "\n",
        "So the basic idea is: We wrap the LCEL chain into a DSPy module - and because DPSy can optimized based on in inputs/outputs of a \"black-box\" we can now treat this module *exactly* as we would any other DSPy module!"
      ],
      "metadata": {
        "id": "Fvfl8idArbdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.predict.langchain import LangChainModule, LangChainPredict\n",
        "\n",
        "zeroshot_chain = (\n",
        "    RunnablePassthrough.assign(context=retrieve)\n",
        "    | LangChainPredict(prompt, llm)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "zeroshot_chain = LangChainModule(\n",
        "    zeroshot_chain\n",
        ")"
      ],
      "metadata": {
        "id": "HsNYyvgMVULS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try out the system we've built!"
      ],
      "metadata": {
        "id": "dBLghnnhu2aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the best part about California?\"\n",
        "\n",
        "zeroshot_chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wfr0lYhUVY0H",
        "outputId": "509282bd-1a14-4016-e3d0-2a8b71865360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"California is the heart of innovation! ğŸŒŸ From Silicon Valley's tech boom to LA's entertainment magic, it offers unmatched opportunities and a vibrant culture. #CaliforniaDreaming #InnovationHub\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Dataset for Evaluation/Optimization\n",
        "\n",
        "In classic form - we'll leverage the OpenAI suite of models to generate test examples that we will then go on to use with DSPy to evaluate, and then optimize and re-evaluate the optimized DSPy module!\n",
        "\n",
        "Our synthetic datagen incorporates the following simple steps:\n",
        "\n",
        "1. Generate a question from the provided context\n",
        "2. Generate a Tweet from the context and question"
      ],
      "metadata": {
        "id": "8TzWhK-Su6hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SAMPLES_TO_GENERATE = 250"
      ],
      "metadata": {
        "id": "saK-9PmvvW4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "question_list = []\n",
        "answer_list = []\n",
        "\n",
        "question_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "question_prompt = PromptTemplate.from_template(\n",
        "    \"Given a context, generate a question that could be answered by that context. You must only respond with the question. Context:\\n{context}\\n\\Question:\\n\"\n",
        ")\n",
        "\n",
        "question_chain = question_prompt | question_llm | StrOutputParser()\n",
        "\n",
        "answer_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "answer_prompt = PromptTemplate.from_template(\n",
        "    \"Given a context and a question, create a tweet about the question and context. You must only respond with the tweet. Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\Tweet:\\n\"\n",
        ")\n",
        "\n",
        "answer_chain = answer_prompt | answer_llm | StrOutputParser()\n",
        "\n",
        "if NUM_SAMPLES_TO_GENERATE > len(split_documents):\n",
        "  NUM_SAMPLES_TO_GENERATE = len(split_documents)\n",
        "  print(f\"WARNING: reducing number of samples to {NUM_SAMPLES_TO_GENERATE}\")\n",
        "\n",
        "for context in tqdm.tqdm(split_documents[:NUM_SAMPLES_TO_GENERATE]):\n",
        "  question = question_chain.invoke({\"context\": context.page_content})\n",
        "  answer = answer_chain.invoke({\"context\": context.page_content, \"question\": question})\n",
        "  question_list.append(question)\n",
        "  answer_list.append(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpOsMjB-fA8u",
        "outputId": "4b391e9b-21ff-4d34-fe6b-ec1006a0d972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [10:46<00:00,  2.58s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to move our newly created data into a more useful form to be used with DSPy."
      ],
      "metadata": {
        "id": "PErV1qQXvU8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy import Example\n",
        "\n",
        "train_samples = int(NUM_SAMPLES_TO_GENERATE * 0.8)\n",
        "dev_samples = int(NUM_SAMPLES_TO_GENERATE * 0.1)\n",
        "val_samples = int(NUM_SAMPLES_TO_GENERATE * 0.1)\n",
        "\n",
        "sample_count = 0\n",
        "\n",
        "train_set = []\n",
        "dev_set = []\n",
        "val_set = []\n",
        "\n",
        "for question, answer in zip(question_list, answer_list):\n",
        "  if sample_count < train_samples:\n",
        "    train_set.append(Example(question=question, answer=answer).with_inputs(\"question\"))\n",
        "  elif sample_count < train_samples + dev_samples:\n",
        "    dev_set.append(Example(question=question, answer=answer).with_inputs(\"question\"))\n",
        "  else:\n",
        "    val_set.append(Example(question=question, answer=answer).with_inputs(\"question\"))\n",
        "  sample_count += 1"
      ],
      "metadata": {
        "id": "TtSwnrl5j9LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create our validation logic - let's dive into the details a bit here.\n",
        "\n",
        "First - we'll create a signature for how we want to evaluate our Tweet.\n",
        "\n",
        "> NOTE: We're using LLM-As-A-Judge here to determine a number of scores that we will collect as \"Yes\" or \"No\"."
      ],
      "metadata": {
        "id": "t-0exnhjv0cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "class Assess(dspy.Signature):\n",
        "    \"\"\"Assess the quality of a tweet along the specified dimension.\"\"\"\n",
        "    context = dspy.InputField(desc=\"ignore if N/A\")\n",
        "    assessed_text = dspy.InputField()\n",
        "    assessment_question = dspy.InputField()\n",
        "    assessment_answer = dspy.OutputField(desc=\"Yes or No\")"
      ],
      "metadata": {
        "id": "5neS4JHGv5Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set up our Judge model."
      ],
      "metadata": {
        "id": "f_t2XqqMwsvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt4T = dspy.OpenAI(model=\"gpt-4-turbo\", max_tokens=1000, model_type=\"chat\")\n",
        "METRIC = None"
      ],
      "metadata": {
        "id": "qyq3KmVwwsTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate on a number of metrics:\n",
        "\n",
        "1. Engaging\n",
        "2. Faithfulness\n",
        "3. Dopeness\n",
        "4. Correctness"
      ],
      "metadata": {
        "id": "Ka0IWrecv6tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metric(gold, pred, trace=None):\n",
        "    question, answer, tweet = gold.question, gold.answer, pred.output\n",
        "    context = retriever.invoke(question)\n",
        "\n",
        "    engaging = \"Does the assessed text make for a self-contained, engaging tweet?\"\n",
        "    faithful = \"Is the assessed text grounded in the context? Say no if it includes significant facts not in the context.\"\n",
        "    dope = f\"Is the assessed text dope, lit, cool, fire?\"\n",
        "    correct = (\n",
        "        f\"The text above should answer `{question}`. The gold answer is `{answer}`.\"\n",
        "        )\n",
        "    correct = f\"{correct} does the assessed text communicate the same idea as the gold answer?\"\n",
        "\n",
        "    with dspy.context(lm=gpt4T):\n",
        "        faithful = dspy.Predict(Assess)(\n",
        "            context=context, assessed_text=tweet, assessment_question=faithful\n",
        "        )\n",
        "        engaging = dspy.Predict(Assess)(\n",
        "            context=\"N/A\", assessed_text=tweet, assessment_question=engaging\n",
        "        )\n",
        "        dope = dspy.Predict(Assess)(\n",
        "            context=\"N/A\", assessed_text=tweet, assessment_question=dope\n",
        "        )\n",
        "        correct = dspy.Predict(Assess)(\n",
        "            context=\"N/A\", assessed_text=tweet, assessment_question=correct\n",
        "        )\n",
        "\n",
        "    correct, engaging, faithful, dope = [\n",
        "        m.assessment_answer.split()[0].lower() == \"yes\"\n",
        "        for m in [correct, engaging, faithful, dope]\n",
        "    ]\n",
        "    score = (engaging + faithful + dope) if correct and (len(tweet) <= 280) else 0\n",
        "\n",
        "    if METRIC is not None:\n",
        "        if METRIC == \"correct\":\n",
        "            return correct\n",
        "        if METRIC == \"engaging\":\n",
        "            return engaging\n",
        "        if METRIC == \"faithful\":\n",
        "            return faithful\n",
        "        if METRIC == \"dope\":\n",
        "            return dope\n",
        "\n",
        "    if trace is not None:\n",
        "        return score >= 3\n",
        "    return score / 3.0"
      ],
      "metadata": {
        "id": "YfkGYgMgdTUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can Evaluate!|"
      ],
      "metadata": {
        "id": "kG_31lo-xwhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.evaluate.evaluate import Evaluate\n",
        "\n",
        "evaluate = Evaluate(\n",
        "    metric=metric, devset=dev_set, num_threads=8, display_progress=True, display_table=5\n",
        ")"
      ],
      "metadata": {
        "id": "Xp0UeGckd9Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(zeroshot_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "sW3nDTv9wJnv",
        "outputId": "7cd059da-8598-41f6-eae2-3388b1f6c28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 31.33333333333334 / 50  (62.7): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 31.33333333333334 / 50  (62.7%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cf86cb78670>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_3a663 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_3a663 td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_3a663_row0_col0, #T_3a663_row0_col1, #T_3a663_row0_col2, #T_3a663_row0_col3, #T_3a663_row0_col4, #T_3a663_row1_col0, #T_3a663_row1_col1, #T_3a663_row1_col2, #T_3a663_row1_col3, #T_3a663_row1_col4, #T_3a663_row2_col0, #T_3a663_row2_col1, #T_3a663_row2_col2, #T_3a663_row2_col3, #T_3a663_row2_col4, #T_3a663_row3_col0, #T_3a663_row3_col1, #T_3a663_row3_col2, #T_3a663_row3_col3, #T_3a663_row3_col4, #T_3a663_row4_col0, #T_3a663_row4_col1, #T_3a663_row4_col2, #T_3a663_row4_col3, #T_3a663_row4_col4 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_3a663\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_3a663_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_3a663_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n",
              "      <th id=\"T_3a663_level0_col2\" class=\"col_heading level0 col2\" >output</th>\n",
              "      <th id=\"T_3a663_level0_col3\" class=\"col_heading level0 col3\" >tweet_response</th>\n",
              "      <th id=\"T_3a663_level0_col4\" class=\"col_heading level0 col4\" >metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_3a663_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_3a663_row0_col0\" class=\"data row0 col0\" >What are the signs that indicate a problem with a newly hired executive in a startup?</td>\n",
              "      <td id=\"T_3a663_row0_col1\" class=\"data row0 col1\" >ğŸš¨ Signs of trouble with a new exec in a startup: 1ï¸âƒ£ Team not noticeably better or respectful after a few months. 2ï¸âƒ£ Other execs...</td>\n",
              "      <td id=\"T_3a663_row0_col2\" class=\"data row0 col2\" >Signs of trouble with a new startup executive: lack of respect from peers, painful interactions, and team performance not improving. If you notice these, itâ€™s...</td>\n",
              "      <td id=\"T_3a663_row0_col3\" class=\"data row0 col3\" >Signs of trouble with a new startup executive: lack of respect from peers, painful interactions, and team performance not improving. If you notice these, itâ€™s...</td>\n",
              "      <td id=\"T_3a663_row0_col4\" class=\"data row0 col4\" >1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3a663_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_3a663_row1_col0\" class=\"data row1 col0\" >What are the two common mistakes people make when firing executives?</td>\n",
              "      <td id=\"T_3a663_row1_col1\" class=\"data row1 col1\" >Two common mistakes when firing execs: 1) Long transition periods - confusing & demoralizing. 2) Pulling punches - be clear & decisive. Clean breaks are...</td>\n",
              "      <td id=\"T_3a663_row1_col2\" class=\"data row1 col2\" >Avoid long transition periods and pulling punches! Make a clean break and put someone new in charge to keep the organization moving forward. #Leadership #StartupTips</td>\n",
              "      <td id=\"T_3a663_row1_col3\" class=\"data row1 col3\" >Avoid long transition periods and pulling punches! Make a clean break and put someone new in charge to keep the organization moving forward. #Leadership #StartupTips</td>\n",
              "      <td id=\"T_3a663_row1_col4\" class=\"data row1 col4\" >0.6666666666666666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3a663_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_3a663_row2_col0\" class=\"data row2 col0\" >What are the potential benefits of terminating an executive's position in a startup?</td>\n",
              "      <td id=\"T_3a663_row2_col1\" class=\"data row2 col1\" >ğŸš€ Terminating an executive at a startup can often be a favor: it frees them to find a better fit where they'll be more valued,...</td>\n",
              "      <td id=\"T_3a663_row2_col2\" class=\"data row2 col2\" >Terminating an executive in a startup can clear the way for better talent, reduce costs, and improve team morale. It often helps the executive find...</td>\n",
              "      <td id=\"T_3a663_row2_col3\" class=\"data row2 col3\" >Terminating an executive in a startup can clear the way for better talent, reduce costs, and improve team morale. It often helps the executive find...</td>\n",
              "      <td id=\"T_3a663_row2_col4\" class=\"data row2 col4\" >0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3a663_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_3a663_row3_col0\" class=\"data row3 col0\" >What is Ben Horowitz's perspective on micromanagement in the context of management practices?</td>\n",
              "      <td id=\"T_3a663_row3_col1\" class=\"data row3 col1\" >Ben Horowitz argues that micromanagement shouldn't be condemned outright. While we all dread the hyper-controlling manager, he believes thereâ€™s value in the practice when applied...</td>\n",
              "      <td id=\"T_3a663_row3_col2\" class=\"data row3 col2\" >Ben Horowitz argues that micromanagement isn't always bad; it can be essential for training and improving new executives. A little micromanagement at the right times...</td>\n",
              "      <td id=\"T_3a663_row3_col3\" class=\"data row3 col3\" >Ben Horowitz argues that micromanagement isn't always bad; it can be essential for training and improving new executives. A little micromanagement at the right times...</td>\n",
              "      <td id=\"T_3a663_row3_col4\" class=\"data row3 col4\" >1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3a663_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_3a663_row4_col0\" class=\"data row4 col0\" >What is \"Task Relevant Maturity\" and how does it relate to micromanaging employees and executives?</td>\n",
              "      <td id=\"T_3a663_row4_col1\" class=\"data row4 col1\" >Ever heard of \"Task Relevant Maturity\"? ğŸ“š Andy Grove explains it in High Output Management: Employees, even execs, need different levels of guidance based on...</td>\n",
              "      <td id=\"T_3a663_row4_col2\" class=\"data row4 col2\" >\"Task Relevant Maturity\" refers to an employee's experience level with a specific task. Micromanaging is beneficial for those who are immature in a task, including...</td>\n",
              "      <td id=\"T_3a663_row4_col3\" class=\"data row4 col3\" >\"Task Relevant Maturity\" refers to an employee's experience level with a specific task. Micromanaging is beneficial for those who are immature in a task, including...</td>\n",
              "      <td id=\"T_3a663_row4_col4\" class=\"data row4 col4\" >1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "                <div style='\n",
              "                    text-align: center; \n",
              "                    font-size: 16px; \n",
              "                    font-weight: bold; \n",
              "                    color: #555; \n",
              "                    margin: 10px 0;'>\n",
              "                    ... 45 more rows not displayed ...\n",
              "                </div>\n",
              "                "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.67"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
        "\n",
        "optimizer = BootstrapFewShotWithRandomSearch(\n",
        "    metric=metric, max_bootstrapped_demos=5, num_candidate_programs=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2liWnIQnTPG",
        "outputId": "5d0f0210-3e94-45f9-dfa1-6518aef2b7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Going to sample between 1 and 5 traces per predictor.\n",
            "Will attempt to train 3 candidate sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_chain = optimizer.compile(zeroshot_chain, trainset=train_set, valset=val_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9-ZcQ2WnXkn",
        "outputId": "16da3b83-185e-4915-9e15-91e77d8f1a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 34.00000000000001 / 50  (68.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:07<00:00,  6.77it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 34.00000000000001 / 50  (68.0%)\n",
            "Score: 68.0 for set: [0]\n",
            "New best score: 68.0 for seed -3\n",
            "Scores so far: [68.0]\n",
            "Best score: 68.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 34.00000000000001 / 50  (68.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.87it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 34.00000000000001 / 50  (68.0%)\n",
            "Score: 68.0 for set: [16]\n",
            "Scores so far: [68.0, 68.0]\n",
            "Best score: 68.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|â–Œ         | 9/150 [00:10<02:44,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 5 full traces after 10 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 33.333333333333336 / 50  (66.7): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:46<00:00,  1.08it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 33.333333333333336 / 50  (66.7%)\n",
            "Score: 66.67 for set: [16]\n",
            "Scores so far: [68.0, 68.0, 66.67]\n",
            "Best score: 68.0\n",
            "Average of max per entry across top 1 scores: 0.6800000000000002\n",
            "Average of max per entry across top 2 scores: 0.6800000000000002\n",
            "Average of max per entry across top 3 scores: 0.7733333333333333\n",
            "Average of max per entry across top 5 scores: 0.7733333333333333\n",
            "Average of max per entry across top 8 scores: 0.7733333333333333\n",
            "Average of max per entry across top 9999 scores: 0.7733333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|â–         | 4/150 [00:03<02:04,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 4 full traces after 5 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 32.66666666666667 / 50  (65.3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  8.03it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 32.66666666666667 / 50  (65.3%)\n",
            "Score: 65.33 for set: [16]\n",
            "Scores so far: [68.0, 68.0, 66.67, 65.33]\n",
            "Best score: 68.0\n",
            "Average of max per entry across top 1 scores: 0.6800000000000002\n",
            "Average of max per entry across top 2 scores: 0.6800000000000002\n",
            "Average of max per entry across top 3 scores: 0.7733333333333333\n",
            "Average of max per entry across top 5 scores: 0.8266666666666665\n",
            "Average of max per entry across top 8 scores: 0.8266666666666665\n",
            "Average of max per entry across top 9999 scores: 0.8266666666666665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|â–         | 3/150 [00:02<01:40,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 4 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 36.66666666666667 / 50  (73.3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.78it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 36.66666666666667 / 50  (73.3%)\n",
            "Score: 73.33 for set: [16]\n",
            "New best score: 73.33 for seed 1\n",
            "Scores so far: [68.0, 68.0, 66.67, 65.33, 73.33]\n",
            "Best score: 73.33\n",
            "Average of max per entry across top 1 scores: 0.7333333333333334\n",
            "Average of max per entry across top 2 scores: 0.8133333333333332\n",
            "Average of max per entry across top 3 scores: 0.8133333333333332\n",
            "Average of max per entry across top 5 scores: 0.84\n",
            "Average of max per entry across top 8 scores: 0.84\n",
            "Average of max per entry across top 9999 scores: 0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/150 [00:00<01:43,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 33.66666666666667 / 50  (67.3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 33.66666666666667 / 50  (67.3%)\n",
            "Score: 67.33 for set: [16]\n",
            "Scores so far: [68.0, 68.0, 66.67, 65.33, 73.33, 67.33]\n",
            "Best score: 73.33\n",
            "Average of max per entry across top 1 scores: 0.7333333333333334\n",
            "Average of max per entry across top 2 scores: 0.8133333333333332\n",
            "Average of max per entry across top 3 scores: 0.8133333333333332\n",
            "Average of max per entry across top 5 scores: 0.8466666666666667\n",
            "Average of max per entry across top 8 scores: 0.8533333333333333\n",
            "Average of max per entry across top 9999 scores: 0.8533333333333333\n",
            "6 candidate programs found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(optimized_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7VUUlFzCni-8",
        "outputId": "f7cf2938-76ff-42aa-de7f-806cfef2e1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 32.666666666666664 / 50  (65.3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 32.666666666666664 / 50  (65.3%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py:130: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(truncate_cell)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cf86ce906a0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_bc7fb th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_bc7fb td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_bc7fb_row0_col0, #T_bc7fb_row0_col1, #T_bc7fb_row0_col2, #T_bc7fb_row0_col3, #T_bc7fb_row0_col4, #T_bc7fb_row1_col0, #T_bc7fb_row1_col1, #T_bc7fb_row1_col2, #T_bc7fb_row1_col3, #T_bc7fb_row1_col4, #T_bc7fb_row2_col0, #T_bc7fb_row2_col1, #T_bc7fb_row2_col2, #T_bc7fb_row2_col3, #T_bc7fb_row2_col4, #T_bc7fb_row3_col0, #T_bc7fb_row3_col1, #T_bc7fb_row3_col2, #T_bc7fb_row3_col3, #T_bc7fb_row3_col4, #T_bc7fb_row4_col0, #T_bc7fb_row4_col1, #T_bc7fb_row4_col2, #T_bc7fb_row4_col3, #T_bc7fb_row4_col4 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_bc7fb\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_bc7fb_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_bc7fb_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n",
              "      <th id=\"T_bc7fb_level0_col2\" class=\"col_heading level0 col2\" >output</th>\n",
              "      <th id=\"T_bc7fb_level0_col3\" class=\"col_heading level0 col3\" >tweet_response</th>\n",
              "      <th id=\"T_bc7fb_level0_col4\" class=\"col_heading level0 col4\" >metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_bc7fb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_bc7fb_row0_col0\" class=\"data row0 col0\" >What are the signs that indicate a problem with a newly hired executive in a startup?</td>\n",
              "      <td id=\"T_bc7fb_row0_col1\" class=\"data row0 col1\" >ğŸš¨ Signs of trouble with a new exec in a startup: 1ï¸âƒ£ Team not noticeably better or respectful after a few months. 2ï¸âƒ£ Other execs...</td>\n",
              "      <td id=\"T_bc7fb_row0_col2\" class=\"data row0 col2\" >Signs of trouble with a new executive in a startup include lack of respect from peers, poor communication, and avoidance in interactions. If these issues...</td>\n",
              "      <td id=\"T_bc7fb_row0_col3\" class=\"data row0 col3\" >Signs of trouble with a new executive in a startup include lack of respect from peers, poor communication, and avoidance in interactions. If these issues...</td>\n",
              "      <td id=\"T_bc7fb_row0_col4\" class=\"data row0 col4\" >1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bc7fb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_bc7fb_row1_col0\" class=\"data row1 col0\" >What are the two common mistakes people make when firing executives?</td>\n",
              "      <td id=\"T_bc7fb_row1_col1\" class=\"data row1 col1\" >Two common mistakes when firing execs: 1) Long transition periods - confusing & demoralizing. 2) Pulling punches - be clear & decisive. Clean breaks are...</td>\n",
              "      <td id=\"T_bc7fb_row1_col2\" class=\"data row1 col2\" >When firing executives, avoid long transition periods and pulling punches. Make a clean break to prevent confusion and demoralization! #Leadership #StartupAdvice</td>\n",
              "      <td id=\"T_bc7fb_row1_col3\" class=\"data row1 col3\" >When firing executives, avoid long transition periods and pulling punches. Make a clean break to prevent confusion and demoralization! #Leadership #StartupAdvice</td>\n",
              "      <td id=\"T_bc7fb_row1_col4\" class=\"data row1 col4\" >1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bc7fb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_bc7fb_row2_col0\" class=\"data row2 col0\" >What are the potential benefits of terminating an executive's position in a startup?</td>\n",
              "      <td id=\"T_bc7fb_row2_col1\" class=\"data row2 col1\" >ğŸš€ Terminating an executive at a startup can often be a favor: it frees them to find a better fit where they'll be more valued,...</td>\n",
              "      <td id=\"T_bc7fb_row2_col2\" class=\"data row2 col2\" >Terminating an executive can lead to a more motivated team, better alignment with startup goals, and the opportunity for the executive to find a role...</td>\n",
              "      <td id=\"T_bc7fb_row2_col3\" class=\"data row2 col3\" >Terminating an executive can lead to a more motivated team, better alignment with startup goals, and the opportunity for the executive to find a role...</td>\n",
              "      <td id=\"T_bc7fb_row2_col4\" class=\"data row2 col4\" >1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bc7fb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_bc7fb_row3_col0\" class=\"data row3 col0\" >What is Ben Horowitz's perspective on micromanagement in the context of management practices?</td>\n",
              "      <td id=\"T_bc7fb_row3_col1\" class=\"data row3 col1\" >Ben Horowitz argues that micromanagement shouldn't be condemned outright. While we all dread the hyper-controlling manager, he believes thereâ€™s value in the practice when applied...</td>\n",
              "      <td id=\"T_bc7fb_row3_col2\" class=\"data row3 col2\" >Ben Horowitz argues that micromanagement can be beneficial in certain situations, especially for new executives who need detailed guidance to improve their skills. It's about...</td>\n",
              "      <td id=\"T_bc7fb_row3_col3\" class=\"data row3 col3\" >Ben Horowitz argues that micromanagement can be beneficial in certain situations, especially for new executives who need detailed guidance to improve their skills. It's about...</td>\n",
              "      <td id=\"T_bc7fb_row3_col4\" class=\"data row3 col4\" >1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bc7fb_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_bc7fb_row4_col0\" class=\"data row4 col0\" >What is \"Task Relevant Maturity\" and how does it relate to micromanaging employees and executives?</td>\n",
              "      <td id=\"T_bc7fb_row4_col1\" class=\"data row4 col1\" >Ever heard of \"Task Relevant Maturity\"? ğŸ“š Andy Grove explains it in High Output Management: Employees, even execs, need different levels of guidance based on...</td>\n",
              "      <td id=\"T_bc7fb_row4_col2\" class=\"data row4 col2\" >\"Task Relevant Maturity\" refers to an employee's experience level with a specific task. Micromanaging is beneficial for those who are immature in a task, including...</td>\n",
              "      <td id=\"T_bc7fb_row4_col3\" class=\"data row4 col3\" >\"Task Relevant Maturity\" refers to an employee's experience level with a specific task. Micromanaging is beneficial for those who are immature in a task, including...</td>\n",
              "      <td id=\"T_bc7fb_row4_col4\" class=\"data row4 col4\" >0.6666666666666666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "                <div style='\n",
              "                    text-align: center; \n",
              "                    font-size: 16px; \n",
              "                    font-weight: bold; \n",
              "                    color: #555; \n",
              "                    margin: 10px 0;'>\n",
              "                    ... 45 more rows not displayed ...\n",
              "                </div>\n",
              "                "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.33"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_used, output = dspy.settings.langchain_history[-1]"
      ],
      "metadata": {
        "id": "JjzliyZFoBPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_used)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5nylzV3oCzu",
        "outputId": "e22cd818-e4c5-4387-ee6d-7340f67e3bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Essential Instructions: Respond to the given question based on the provided context. Your answer should be concise and formatted as if it were a tweet. Ensure that the response does not exceed the Twitter character limit and is appropriate for a public audience.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Context: ${context}\n",
            "Question: ${question}\n",
            "Tweet Response: ${tweet_response}\n",
            "\n",
            "---\n",
            "\n",
            "Context:\n",
            "[1] Â«companies can oaen tolerate internal rivalries and warfare;\n",
            "startups cannot.\n",
            "Being a startup executive is not an easy job. The rewards are\n",
            "substantial â€” the ability to contribute directly to the startupsâ€™s\n",
            "success; the latitude to build and run an organization according\n",
            "to her own theories and principles; and a meaningful equity\n",
            "stake that can lead to personal Xnancial independence if the\n",
            "startup succeeds â€” but the responsibilities are demanding and\n",
            "intense.\n",
            "Hiring\n",
            "First, if youâ€™re not sure whether you need an executive for a function,\n",
            "donâ€™t hire one.\n",
            "Startups, particularly well-funded startups, oaen hire executives\n",
            "too early. Particularly before a startup has achieved product/\n",
            "market Xt, it is oMen better to have a highly motivated manager or\n",
            "director running a function than an executive.\n",
            "Hiring an executive too quickly can lead to someone who is\n",
            "really expensive, sitting there in the middle of the room, doing\n",
            "very little. Not good for the executive, not good for the rest ofÂ»\n",
            "[2] Â«Eighth, recognize that hiring an executive is a high-risk proposition.\n",
            "You oaen see a startup with a screwed up development process,\n",
            "but â€œwhen we get our VP of Engineering onboard, everything\n",
            "will get Xxedâ€. Or a startup that is missing its revenue targets, but\n",
            "â€œwhen we get our VP of sales, reveue will take oWâ€.\n",
            "Hereâ€™s the problem: in my experience, if you know what youâ€™re\n",
            "doing, the odds of a given executive hire working out will be about\n",
            "Part 8: Hiring, managing, promoting, and Dring executives\n",
            "59Â»\n",
            "[3] Â«from scratch. This is a sharp diWerence from many big\n",
            "company executives, who can spend their entire careers\n",
            "running organizations other people built â€” oaen years or\n",
            "decades earlier.\n",
            "â€¢\n",
            "Be a primary individual contributorâ€“ a startup executive\n",
            "must â€œroll up her sleevesâ€ and produce output herself. There\n",
            "are no shortage of critical things to be done at a startup, and\n",
            "an executive who cannot personally produce while\n",
            "simultaneously building and running her organization\n",
            "typically will not last long. Again, this is a sharp diWerence\n",
            "from many big companies, where executives oaen serve\n",
            "more as administrators and bureaucrats.\n",
            "â€¢\n",
            "Be a team playerâ€“ a startup executive must take personal\n",
            "responsibility for her relationships with her peers and people\n",
            "throughout the startup, in all functions and at all levels. Big\n",
            "companies can oaen tolerate internal rivalries and warfare;\n",
            "startups cannot.\n",
            "Being a startup executive is not an easy job. The rewards areÂ»\n",
            "[4] Â«very big problem to end up with â€” be very careful.\n",
            "â€¢\n",
            "Donâ€™t disqualify someone based on ego or cockinessâ€“ as long as\n",
            "sheâ€™s not insane. Great executives are high-ego â€” you want\n",
            "someone driven to run things, driven to make decisions,\n",
            "conXdent in herself and her abilities. I donâ€™t mean loud and\n",
            "obnoxious, I mean assured and determined, bleeding over\n",
            "into cocky. If a VCâ€™s ideal investment is a company that will\n",
            "succceed without him, then your ideal executive hire is someone who\n",
            "will succeed without you.\n",
            "â€¢\n",
            "Beware hiring a big company executive for a startup.The\n",
            "executive skill sets required for a big company vs a startup\n",
            "are very Even great big company executives frequently\n",
            "have no idea what to do once they arrive at a startup.\n",
            "â€¢\n",
            "In particular, really beware hiring an executive from an incredibly\n",
            "successful big company. This is oaen very tempting â€” who\n",
            "wouldnâ€™t want to bring onboard someone who sprinkles\n",
            "some of that IBM (in the 80â€™s), Microsoa (in the 90â€™s), orÂ»\n",
            "Question: What are the risks associated with hiring an executive in a startup?\n",
            "Tweet Response: Hiring an executive in a startup is high-risk! ğŸš¨ You might end up with someone expensive who does little, or a big company exec who can't adapt. Ensure they can contribute and thrive in a fast-paced environment! #StartupLife #HiringRisks\n",
            "\n",
            "---\n",
            "\n",
            "Context:\n",
            "[1] Â«Part 1: Why not to do a startup\n",
            "In this series of posts I will walk through some of my accumu-\n",
            "lated knowledge and experience in building high-tech startups.\n",
            "My speciXc experience is from three companies I have co-\n",
            "founded: Netscape, sold to America Online in 1998 for $4.2\n",
            "billion; Opsware (formerly Loudcloud), a public soaware com-\n",
            "pany with an approximately $1 billion market cap; and now\n",
            "Ning, a new, private consumer Internet company.\n",
            "But more generally, Iâ€™ve been fortunate enough to be involved\n",
            "in and exposed to a broad range of other startups â€” maybe 40\n",
            "or 50 in enough detail to know what Iâ€™m talking about â€” since\n",
            "arriving in Silicon Valley in 1994: as a board member, as an angel\n",
            "investor, as an advisor, as a friend of various founders, and as a\n",
            "participant in various venture capital funds.\n",
            "This series will focus on lessons learned from this entire cross-\n",
            "section of Silicon Valley startups â€” so donâ€™t think that anything\n",
            "I am talking about is referring to one of my own companies:Â»\n",
            "[2] Â«Second, in a startup, absolutely nothing happens unless you make it\n",
            "happen.\n",
            "This one throws both founders and employees new to startups.\n",
            "In an established company â€” no matter how poorly run or\n",
            "demoralized â€” things happen. They just happen. People come\n",
            "in to work. Code gets written. User interfaces get designed.\n",
            "Servers get provisioned. Markets get analyzed. Pricing gets stud-\n",
            "ied and determined. Sales calls get made. The wastebaskets get\n",
            "emptied. And so on.\n",
            "A startup has none of the established systems, rhythms, infra-\n",
            "structure that any established company has.\n",
            "In a startup it is very easy for the code to not get written, for the\n",
            "user interfaces to not get designedâ€¦ for people to not come into\n",
            "workâ€¦ and for the wastebaskets to not get emptied.\n",
            "You as the founder have to put all of these systems and routines\n",
            "and habits in place and get everyone actually rowing â€” forget\n",
            "even about rowing in the right direction: just rowing at all is\n",
            "hard enough at the start.Â»\n",
            "[3] Â«technologies? Or, are global in perspective from day one? You\n",
            "get to choose, and to build your culture and team to suit.\n",
            "And Xnally, money â€” startups done right can of course be highly\n",
            "lucrative. This is not just an issue of personal greed â€” when\n",
            "things go right, your team and employees will themselves do\n",
            "very well and will be able to support their families, send their\n",
            "kids to college, and realize their dreams, and thatâ€™s really cool.\n",
            "And if youâ€™re really lucky, you as the entrepreneur can ulti-\n",
            "mately make profound philanthropic gias that change society\n",
            "for the better.\n",
            "However, there are many more reasons to no\n",
            "not\n",
            "t do a startup.\n",
            "First, and most importantly, realize that a startup puts you on\n",
            "an emotional rollercoaster unlike anything you have ever experi-\n",
            "enced.\n",
            "You will Yip rapidly from a day in which you are euphorically\n",
            "convinced you are going to own the world, to a day in which\n",
            "doom seems only weeks away and you feel completely ruined,\n",
            "and back again.\n",
            "Over and over and over.Â»\n",
            "[4] Â«This series will focus on lessons learned from this entire cross-\n",
            "section of Silicon Valley startups â€” so donâ€™t think that anything\n",
            "I am talking about is referring to one of my own companies:\n",
            "most likely when I talk about a scenario I have seen or some-\n",
            "thing I have experienced, it is from some other startup that I\n",
            "am not naming but was involved with some other way than as a\n",
            "founder.\n",
            "Finally, much of my perspective is based on Silicon Valley and\n",
            "the environment that we have here â€” the culture, the people,\n",
            "the venture capital base, and so on. Some of it will travel wellÂ»\n",
            "Question: What experiences does the author draw from in discussing the challenges of starting a startup?\n",
            "Tweet Response: The author shares insights from co-founding Netscape, Opsware, and Ning, plus involvement with 40-50 other startups in Silicon Valley, highlighting the emotional rollercoaster and unique challenges of startup life. #StartupLife #Entrepreneurship\n",
            "\n",
            "---\n",
            "\n",
            "Context:\n",
            "[1] Â«ably also has an overstaZng problem and a mediocrity problem\n",
            "and needs to Xx both of those at the same time.\n",
            "Identify and eliminate the jobs of the following categories of\n",
            "people:\n",
            "88\n",
            "The Pmarca Blog ArchivesÂ»\n",
            "[2] Â«Competition risk â€” are there too many other startups already\n",
            "doing this? Is this startup suZciently diWerentiated from the\n",
            "other startups, and also diWerentiated from any large incum-\n",
            "bents?\n",
            "Timing risk â€” is it too early? Is it too late?\n",
            "Financing risk â€” aaer we invest in this round, how many addi-\n",
            "tional rounds of Xnancing will be required for the company to\n",
            "become proXtable, and what will the dollar total be? How certain\n",
            "are we about these estimates? How do we know?\n",
            "Marketing risk â€” will this startup be able to cut through the\n",
            "noise? How much will marketing cost? Do the economics of cus-\n",
            "tomer acquisition â€” the cost to acquire a customer, and the rev-\n",
            "enue that customer will generate â€” work?\n",
            "Distribution risk â€” does this startup need certain distribution\n",
            "partners to succeed? Will it be able to get them? How? (For\n",
            "example, this is a common problem with mobile startups that\n",
            "need deals with major mobile carriers to succeed.)Â»\n",
            "[3] Â«partners to succeed? Will it be able to get them? How? (For\n",
            "example, this is a common problem with mobile startups that\n",
            "need deals with major mobile carriers to succeed.)\n",
            "Technology risk â€” can the product be built? Does it involve rocket\n",
            "science â€” or an equivalent, like artiXcial intelligence or natural\n",
            "language processing? Are there fundamental breakthroughs that\n",
            "need to happen? If so, how certain are we that they will happen,\n",
            "or that this team will be able to make them?\n",
            "Product risk â€” even assuming the product can in theory be built,\n",
            "can this team build it?\n",
            "Hiring risk â€” what positions does the startup need to hire for in\n",
            "order to execute its plan? E.g. a startup planning to build a high-\n",
            "scale web service will need a VP of Operations â€” will the found-\n",
            "ing team be able to hire a good one?\n",
            "Location risk â€” where is the startup located? Can it hire the right\n",
            "talent in that location? And will I as the VC need to drive more\n",
            "than 20 minutes in my Mercedes SLR McLaren to get there?Â»\n",
            "[4] Â«you will need get as far as you can on each round and demon-\n",
            "strate progress towards Product/Market Fit when you raise each\n",
            "new round.\n",
            "If you are ALer Product/Market Fit and you canâ€™t raise enough\n",
            "money in one shot to fully exploit your opportunity, you have\n",
            "a high-class problem and will probably â€” but not deXnitely â€”\n",
            "Xnd that it gets continually easier to raise new money as you\n",
            "need it.\n",
            "What if you donâ€™t want to raise that much\n",
            "money at once?\n",
            "You can argue you should raise a smaller amount of money at\n",
            "a time, because if you are making progress â€” either BPMF or\n",
            "APMF â€” you can raise the rest of the money you need later, at\n",
            "a higher valuation, and give away less of the company.\n",
            "This is the reason some entrepreneurs who can raise a lot of\n",
            "money choose to hold back.\n",
            "42\n",
            "The Pmarca Blog ArchivesÂ»\n",
            "Question: What challenges does Ably face that need to be addressed simultaneously?\n",
            "Tweet Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demos = [\n",
        "    eg\n",
        "    for eg in optimized_chain.modules[0].demos\n",
        "    if hasattr(eg, \"augmented\") and eg.augmented\n",
        "]"
      ],
      "metadata": {
        "id": "crMufr_EoFZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWme5zzdoKGb",
        "outputId": "527b502e-785a-40d2-8a2b-cc94f828736e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Example({'augmented': True, 'question': 'What are the risks associated with hiring an executive in a startup?', 'context': ['companies can oaen tolerate internal rivalries and warfare;\\nstartups cannot.\\nBeing a startup executive is not an easy job. The rewards are\\nsubstantial â€” the ability to contribute directly to the startupsâ€™s\\nsuccess; the latitude to build and run an organization according\\nto her own theories and principles; and a meaningful equity\\nstake that can lead to personal Xnancial independence if the\\nstartup succeeds â€” but the responsibilities are demanding and\\nintense.\\nHiring\\nFirst, if youâ€™re not sure whether you need an executive for a function,\\ndonâ€™t hire one.\\nStartups, particularly well-funded startups, oaen hire executives\\ntoo early. Particularly before a startup has achieved product/\\nmarket Xt, it is oMen better to have a highly motivated manager or\\ndirector running a function than an executive.\\nHiring an executive too quickly can lead to someone who is\\nreally expensive, sitting there in the middle of the room, doing\\nvery little. Not good for the executive, not good for the rest of', 'Eighth, recognize that hiring an executive is a high-risk proposition.\\nYou oaen see a startup with a screwed up development process,\\nbut â€œwhen we get our VP of Engineering onboard, everything\\nwill get Xxedâ€. Or a startup that is missing its revenue targets, but\\nâ€œwhen we get our VP of sales, reveue will take oWâ€.\\nHereâ€™s the problem: in my experience, if you know what youâ€™re\\ndoing, the odds of a given executive hire working out will be about\\nPart 8: Hiring, managing, promoting, and Dring executives\\n59', 'from scratch. This is a sharp diWerence from many big\\ncompany executives, who can spend their entire careers\\nrunning organizations other people built â€” oaen years or\\ndecades earlier.\\nâ€¢\\nBe a primary individual contributorâ€“ a startup executive\\nmust â€œroll up her sleevesâ€ and produce output herself. There\\nare no shortage of critical things to be done at a startup, and\\nan executive who cannot personally produce while\\nsimultaneously building and running her organization\\ntypically will not last long. Again, this is a sharp diWerence\\nfrom many big companies, where executives oaen serve\\nmore as administrators and bureaucrats.\\nâ€¢\\nBe a team playerâ€“ a startup executive must take personal\\nresponsibility for her relationships with her peers and people\\nthroughout the startup, in all functions and at all levels. Big\\ncompanies can oaen tolerate internal rivalries and warfare;\\nstartups cannot.\\nBeing a startup executive is not an easy job. The rewards are', 'very big problem to end up with â€” be very careful.\\nâ€¢\\nDonâ€™t disqualify someone based on ego or cockinessâ€“ as long as\\nsheâ€™s not insane. Great executives are high-ego â€” you want\\nsomeone driven to run things, driven to make decisions,\\nconXdent in herself and her abilities. I donâ€™t mean loud and\\nobnoxious, I mean assured and determined, bleeding over\\ninto cocky. If a VCâ€™s ideal investment is a company that will\\nsuccceed without him, then your ideal executive hire is someone who\\nwill succeed without you.\\nâ€¢\\nBeware hiring a big company executive for a startup.The\\nexecutive skill sets required for a big company vs a startup\\nare very Even great big company executives frequently\\nhave no idea what to do once they arrive at a startup.\\nâ€¢\\nIn particular, really beware hiring an executive from an incredibly\\nsuccessful big company. This is oaen very tempting â€” who\\nwouldnâ€™t want to bring onboard someone who sprinkles\\nsome of that IBM (in the 80â€™s), Microsoa (in the 90â€™s), or'], 'tweet_response': \"Hiring an executive in a startup is high-risk! ğŸš¨ You might end up with someone expensive who does little, or a big company exec who can't adapt. Ensure they can contribute and thrive in a fast-paced environment! #StartupLife #HiringRisks\"}) (input_keys=None),\n",
              " Example({'augmented': True, 'question': 'What experiences does the author draw from in discussing the challenges of starting a startup?', 'context': ['Part 1: Why not to do a startup\\nIn this series of posts I will walk through some of my accumu-\\nlated knowledge and experience in building high-tech startups.\\nMy speciXc experience is from three companies I have co-\\nfounded: Netscape, sold to America Online in 1998 for $4.2\\nbillion; Opsware (formerly Loudcloud), a public soaware com-\\npany with an approximately $1 billion market cap; and now\\nNing, a new, private consumer Internet company.\\nBut more generally, Iâ€™ve been fortunate enough to be involved\\nin and exposed to a broad range of other startups â€” maybe 40\\nor 50 in enough detail to know what Iâ€™m talking about â€” since\\narriving in Silicon Valley in 1994: as a board member, as an angel\\ninvestor, as an advisor, as a friend of various founders, and as a\\nparticipant in various venture capital funds.\\nThis series will focus on lessons learned from this entire cross-\\nsection of Silicon Valley startups â€” so donâ€™t think that anything\\nI am talking about is referring to one of my own companies:', 'Second, in a startup, absolutely nothing happens unless you make it\\nhappen.\\nThis one throws both founders and employees new to startups.\\nIn an established company â€” no matter how poorly run or\\ndemoralized â€” things happen. They just happen. People come\\nin to work. Code gets written. User interfaces get designed.\\nServers get provisioned. Markets get analyzed. Pricing gets stud-\\nied and determined. Sales calls get made. The wastebaskets get\\nemptied. And so on.\\nA startup has none of the established systems, rhythms, infra-\\nstructure that any established company has.\\nIn a startup it is very easy for the code to not get written, for the\\nuser interfaces to not get designedâ€¦ for people to not come into\\nworkâ€¦ and for the wastebaskets to not get emptied.\\nYou as the founder have to put all of these systems and routines\\nand habits in place and get everyone actually rowing â€” forget\\neven about rowing in the right direction: just rowing at all is\\nhard enough at the start.', 'technologies? Or, are global in perspective from day one? You\\nget to choose, and to build your culture and team to suit.\\nAnd Xnally, money â€” startups done right can of course be highly\\nlucrative. This is not just an issue of personal greed â€” when\\nthings go right, your team and employees will themselves do\\nvery well and will be able to support their families, send their\\nkids to college, and realize their dreams, and thatâ€™s really cool.\\nAnd if youâ€™re really lucky, you as the entrepreneur can ulti-\\nmately make profound philanthropic gias that change society\\nfor the better.\\nHowever, there are many more reasons to no\\nnot\\nt do a startup.\\nFirst, and most importantly, realize that a startup puts you on\\nan emotional rollercoaster unlike anything you have ever experi-\\nenced.\\nYou will Yip rapidly from a day in which you are euphorically\\nconvinced you are going to own the world, to a day in which\\ndoom seems only weeks away and you feel completely ruined,\\nand back again.\\nOver and over and over.', 'This series will focus on lessons learned from this entire cross-\\nsection of Silicon Valley startups â€” so donâ€™t think that anything\\nI am talking about is referring to one of my own companies:\\nmost likely when I talk about a scenario I have seen or some-\\nthing I have experienced, it is from some other startup that I\\nam not naming but was involved with some other way than as a\\nfounder.\\nFinally, much of my perspective is based on Silicon Valley and\\nthe environment that we have here â€” the culture, the people,\\nthe venture capital base, and so on. Some of it will travel well'], 'tweet_response': 'The author shares insights from co-founding Netscape, Opsware, and Ning, plus involvement with 40-50 other startups in Silicon Valley, highlighting the emotional rollercoaster and unique challenges of startup life. #StartupLife #Entrepreneurship'}) (input_keys=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}